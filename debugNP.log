entering function "readVencoInput"
source:
@logit
def readVencoInput(linkConfig):
    '''
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param linkConfig: The config link where all links are given.
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    '''

    linkDict = initializeLinkMgr(readVencoConfig(linkConfig))

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "readVencoConfig"
source:
@logit
def readVencoConfig(cfgLink):
    config = yaml.load(open(cfgLink), Loader=yaml.SafeLoader)
    return config

function call took 0.008994579315185547 ms
exiting function "readVencoConfig"
entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    linkDict_out = {'linkScalars': vencoConfig['linksAbsolute']['inputData'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksAbsolute']['inputData'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksAbsolute']['inputData'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksAbsolute']['REMixTimeseriesPath'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksAbsolute']['OutputPath']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    # review general remark (RESOLVED), a file link implies a sym link on the disk. Have you considered renaming the
    # variable to filePath for example, which would imply a path to a file on the disk
    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:E",
                              skiprows=0)
    scalar = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    scalarsOut = scalar.set_index('parameter')
    return scalarsOut

function call took 0.0650031566619873 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(file_link):
    inputRaw = pd.read_csv(file_link, header=4)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.07699275016784668 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(file_link):
    inputRaw = pd.read_csv(file_link, header=4)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.11999893188476562 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.0789952278137207 ms
exiting function "stringToBoolean"
function call took 0.2019963264465332 ms
exiting function "readInputBoolean"
function call took 0.3589973449707031 ms
exiting function "readVencoInput"
entering function "readVencoInput"
source:
@logit
def readVencoInput(linkConfig):
    '''
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param linkConfig: The config link where all links are given.
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    '''

    linkDict = initializeLinkMgr(readVencoConfig(linkConfig))

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "readVencoConfig"
source:
@logit
def readVencoConfig(cfgLink):
    config = yaml.load(open(cfgLink), Loader=yaml.SafeLoader)
    return config

function call took 0.01199960708618164 ms
exiting function "readVencoConfig"
entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    # review general remark (RESOLVED), a file link implies a sym link on the disk. Have you considered renaming the
    # variable to filePath for example, which would imply a path to a file on the disk
    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:E",
                              skiprows=0)
    scalar = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    scalarsOut = scalar.set_index('parameter')
    return scalarsOut

function call took 0.09700703620910645 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(file_link):
    inputRaw = pd.read_csv(file_link, header=4)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.09600543975830078 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(file_link):
    inputRaw = pd.read_csv(file_link, header=4)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.13099384307861328 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.10200715065002441 ms
exiting function "stringToBoolean"
function call took 0.23800301551818848 ms
exiting function "readInputBoolean"
function call took 0.4570012092590332 ms
exiting function "readVencoInput"
entering function "readVencoInput"
source:
@logit
def readVencoInput(linkConfig):
    '''
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param linkConfig: The config link where all links are given.
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    '''

    linkDict = initializeLinkMgr(readVencoConfig(linkConfig))

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "readVencoConfig"
source:
@logit
def readVencoConfig(cfgLink):
    config = yaml.load(open(cfgLink), Loader=yaml.SafeLoader)
    return config

function call took 0.0040018558502197266 ms
exiting function "readVencoConfig"
entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    # review general remark (RESOLVED), a file link implies a sym link on the disk. Have you considered renaming the
    # variable to filePath for example, which would imply a path to a file on the disk
    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:E",
                              skiprows=0)
    scalar = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    scalarsOut = scalar.set_index('parameter')
    return scalarsOut

function call took 0.03996586799621582 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(file_link):
    inputRaw = pd.read_csv(file_link, header=4)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.07799553871154785 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(file_link):
    inputRaw = pd.read_csv(file_link, header=4)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.11999821662902832 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.10299825668334961 ms
exiting function "stringToBoolean"
function call took 0.2259988784790039 ms
exiting function "readInputBoolean"
function call took 0.3530008792877197 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    '''
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Raw drive profiles.
    :param plugProfiles_raw: Raw plug profiles.
    :param indices: Index columns that are assigned as indices.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns

    '''

    driveProfile = driveProfiles_raw.set_index(list(indices))
    plugProfile = plugProfiles_raw.set_index(list(indices))
    # review: the brackets around config are not necessary as they will be removed by python anyway. Return is not a function but a statement
    return (driveProfile, plugProfile)

function call took 0.020001649856567383 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    '''
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile.

    '''

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfiles_in = len(driveProfiles_raw)
    noPlugProfiles_in = len(plugProfiles_raw)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfiles_in': noDriveProfiles_in,
                   'noPlugProfiles_in': noPlugProfiles_in}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    '''
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :return: Returns the consumption profile in same format and length as driveProfiles but scaled with the specific
    consumption assumption.

    '''

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float division and thus a typecast might not even be necessary
    consumptionProfiles = consumptionProfiles * float(scalars.loc['Verbrauch NEFZ CD', 'value']) / 100
    return consumptionProfiles

function call took 0.04900550842285156 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :return: Returns scaled plugProfile in the same format as plugProfiles.

    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Panschluss', 'value'])
    return chargeProfiles

function call took 0.024003028869628906 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    '''
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.

    '''

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery size', 'value'] * scalars.loc['SoCmin', 'value']
    batCapMax = scalars.loc['Battery size', 'value'] * scalars.loc['SoCmax', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 1.1899988651275635 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    '''
    Calculates the uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.

    '''

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        # testing line
        # chargeMaxProfile.ix[3, '0'] = 15.0
        # if idx == 0:
        #     chargeProfilesUncontrolled[str(0)] = np.where(
        #         chargeMaxProfiles[str(0)] >= chargeMaxProfiles[str(nHours-1)],
        #         chargeMaxProfiles[str(0)] - chargeMaxProfiles[str(nHours-1)],
        #         0)

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)])/2
    return chargeProfilesUncontrolled

function call took 0.03199577331542969 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    '''
    Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.

    '''

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool. I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Verbrauch NEFZ CD', 'value']
    consumptionFuel = scalars.loc['Verbrauch NEFZ CS', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review: have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for idx in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if idx != 0:
            driveProfilesFuelAux[str(idx)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(idx)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(idx)] -
                                              (chargeMaxProfiles[str(idx - 1)] - chargeMaxProfiles[str(idx)]))
    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)])/2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.09299874305725098 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    '''
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
    consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
    and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
    format as chargeProfiles, consumptionProfiles and other input parameters.

    '''

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype and create all kind of wired errors. Especially if there are columns with similar names only differing in whitespaces. This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery size', 'value'] * scalars.loc['SoCmin', 'value']
    batCapMax = scalars.loc['Battery size', 'value'] * scalars.loc['SoCmax', 'value']
    consElectric = scalars.loc['Verbrauch NEFZ CD', 'value']
    consGasoline = scalars.loc['Verbrauch NEFZ CS', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # testing line
            # chargeMinProfiles.ix[3, '0'] = 15.0

            # review the above nHours implies, that the number of hours can vary based on user input or the underlying data. It seems to me risky to hardcode 23 here if the last hour is meant. Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == 23:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 1.2729806900024414 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNumberProfiles"
source:
@logit
def createRandNumberProfiles(driveProfiles, setSeed=1):
    # review for me the function name is not precise. The function creates to my understanding a random profile. If this is the case, I would name it accordingly.
    '''
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.

    '''
    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNos = idxData.loc[:, 'randNo']
    return randNos

function call took 0.010956048965454102 ms
exiting function "createRandNumberProfiles"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    # FIXME Maybe make this function neater by giving filtering functions as params or in a separate file??

    '''
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.

    '''

    boolBEV = scalars.loc['EREV oder BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery size', 'value']
    socMax = scalars.loc['SoCmax', 'value']
    socMin = scalars.loc['SoCmin', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.0859987735748291 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    '''
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars:
    :param filterCons:
    :param scalarsProc:
    :param filterIndex:
    :return:
    :param dmgrName: 'electricPowerProfiles'
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet. Stores the profile in the
    Data Manager under the key specified by dmgrName.
    '''

    consumptionPower = scalars.loc['Verbrauch NEFZ CD', 'value']
    consumptionFuel = scalars.loc['Verbrauch NEFZ CS', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    # datalogger.info(indexCons)
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for idx in range(nHours):
        electricPowerProfiles[str(idx)] = (consumptionProfiles[str(idx)] - driveProfilesFuelAux[str(idx)] *
                                           (consumptionPower / consumptionFuel))

        if filterIndex == 'indexCons':
            electricPowerProfiles[str(idx)] = electricPowerProfiles[str(idx)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(idx)] = electricPowerProfiles[str(idx)] * indexDSM
    return electricPowerProfiles

function call took 0.044008493423461914 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    '''
    Sets all profile values with indexDSM = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    '''

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.05899810791015625 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.031002521514892578 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    '''
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    '''

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    # elif params['filter'] == "profile"
    # ToDo: Profile specific filtering
    else:
        # review have you considered implementing your own error like class FilterError(Exception): pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.0599970817565918 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReference):
    # ToDo: Implement a normalization to the maximum of a given profile

    '''
    Normalizes given profiles with a given scalar reference.

    :param scalars: Input scalars for VencoPy for e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReference: Reference that is taken for normalization. This has to be given in scalar input data.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    '''

    normReference = scalars.loc[normReference, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens? As I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.001012563705444336 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    '''
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profiles: profile identifiers given as list of strings referencing to DataManager keys
    :param dmgrNames: Identifiers given as list of string to store filtered profiles back into the DataManager
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    '''

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure, so that it has not to be passed directly between functions? A class could achieve this goal easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0029811859130859375 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    '''
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profiles: profile identifiers given as list of strings referencing to DataManager keys
    :param dmgrNames: Identifiers given as list of string to store filtered profiles back into the DataManager
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    '''

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure, so that it has not to be passed directly between functions? A class could achieve this goal easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0049970149993896484 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    '''
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profiles: profile identifiers given as list of strings referencing to DataManager keys
    :param dmgrNames: Identifiers given as list of string to store filtered profiles back into the DataManager
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    '''

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure, so that it has not to be passed directly between functions? A class could achieve this goal easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.007001399993896484 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    '''
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profiles: profile identifiers given as list of strings referencing to DataManager keys
    :param dmgrNames: Identifiers given as list of string to store filtered profiles back into the DataManager
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    '''

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure, so that it has not to be passed directly between functions? A class could achieve this goal easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.005999088287353516 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    '''
    This action aggregates all single-vehicle profiles that are considered to one fleet profile. There is a separate
    action for the aggregation of plug profiles since it is not corrected by another driving cycle such as consumption
    related profiles.

    :param profiles: DataManager key of the plug profiles subject to aggregation
    :return: Writes profile to DataManager under the key 'chargeAvailProfile_out'
    '''

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.053005218505859375 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    '''
    This action aggregates all single-vehicle profiles that are considered to one fleet profile. There is a separate
    action for the aggregation of plug profiles since it is not corrected by another driving cycle such as consumption
    related profiles.

    :param profiles: DataManager key of the plug profiles subject to aggregation
    :return: Writes profile to DataManager under the key 'chargeAvailProfile_out'
    '''

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.0479886531829834 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    '''
    This action aggregates all single-vehicle profiles that are considered to one fleet profile. There is a separate
    action for the aggregation of plug profiles since it is not corrected by another driving cycle such as consumption
    related profiles.

    :param profiles: DataManager key of the plug profiles subject to aggregation
    :return: Writes profile to DataManager under the key 'chargeAvailProfile_out'
    '''

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.04599571228027344 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    '''
    This action aggregates all single-vehicle profiles that are considered to one fleet profile. There is a separate
    action for the aggregation of plug profiles since it is not corrected by another driving cycle such as consumption
    related profiles.

    :param profiles: DataManager key of the plug profiles subject to aggregation
    :return: Writes profile to DataManager under the key 'chargeAvailProfile_out'
    '''

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.03400397300720215 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profiles, profType):
    '''
    This action scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param profiles: A list of strings giving the keys of the profile types that should be corrected according to the
    ARTEMIS drive cycle.
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :param dmgrNames: List of strings specifying the keys under which the resulting profile types will be written to
    the DataManager.
    :return: Writes the corrected profiles to the DataManager under the keys given in dmgrNames
    '''

    profilesOut = profiles.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Verbrauch NEFZ CD', 'value']
        consumptionElectricArtemis = scalars.loc['Verbrauch Artemis mit NV CD', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Verbrauch NEFZ CS', 'value']
        consumptionFuelArtemis = scalars.loc['Verbrauch Artemis mit NV CS', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profiles.index:
        profilesOut[colIdx] = corrFactor * profiles[colIdx]
    return profilesOut

function call took 0.0010006427764892578 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profiles, profType):
    '''
    This action scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param profiles: A list of strings giving the keys of the profile types that should be corrected according to the
    ARTEMIS drive cycle.
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :param dmgrNames: List of strings specifying the keys under which the resulting profile types will be written to
    the DataManager.
    :return: Writes the corrected profiles to the DataManager under the keys given in dmgrNames
    '''

    profilesOut = profiles.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Verbrauch NEFZ CD', 'value']
        consumptionElectricArtemis = scalars.loc['Verbrauch Artemis mit NV CD', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Verbrauch NEFZ CS', 'value']
        consumptionFuelArtemis = scalars.loc['Verbrauch Artemis mit NV CS', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profiles.index:
        profilesOut[colIdx] = corrFactor * profiles[colIdx]
    return profilesOut

function call took 0.0010046958923339844 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profiles, profType):
    '''
    This action scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param profiles: A list of strings giving the keys of the profile types that should be corrected according to the
    ARTEMIS drive cycle.
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :param dmgrNames: List of strings specifying the keys under which the resulting profile types will be written to
    the DataManager.
    :return: Writes the corrected profiles to the DataManager under the keys given in dmgrNames
    '''

    profilesOut = profiles.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Verbrauch NEFZ CD', 'value']
        consumptionElectricArtemis = scalars.loc['Verbrauch Artemis mit NV CD', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Verbrauch NEFZ CS', 'value']
        consumptionFuelArtemis = scalars.loc['Verbrauch Artemis mit NV CS', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profiles.index:
        profilesOut[colIdx] = corrFactor * profiles[colIdx]
    return profilesOut

function call took 0.0009980201721191406 ms
exiting function "correctProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # review the int type cast could have a nasty side effect, as it is behaving like a floor operation for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # review this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this: df[nodes] = 0 instead of the explicit loop. I am not 100% sure of the syntax but there is a way to write this without a loop. Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.4360098838806152 ms
exiting function "createEmptyDataFrame"
function call took 2.851893186569214 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # review the int type cast could have a nasty side effect, as it is behaving like a floor operation for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # review this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this: df[nodes] = 0 instead of the explicit loop. I am not 100% sure of the syntax but there is a way to write this without a loop. Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.7310566902160645 ms
exiting function "createEmptyDataFrame"
function call took 3.146000623703003 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # review the int type cast could have a nasty side effect, as it is behaving like a floor operation for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # review this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this: df[nodes] = 0 instead of the explicit loop. I am not 100% sure of the syntax but there is a way to write this without a loop. Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.5640015602111816 ms
exiting function "createEmptyDataFrame"
function call took 2.995002031326294 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # review the int type cast could have a nasty side effect, as it is behaving like a floor operation for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # review this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this: df[nodes] = 0 instead of the explicit loop. I am not 100% sure of the syntax but there is a way to write this without a loop. Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.57100248336792 ms
exiting function "createEmptyDataFrame"
function call took 3.0340003967285156 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # review the int type cast could have a nasty side effect, as it is behaving like a floor operation for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # review this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this: df[nodes] = 0 instead of the explicit loop. I am not 100% sure of the syntax but there is a way to write this without a loop. Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.393002510070801 ms
exiting function "createEmptyDataFrame"
function call took 2.8109965324401855 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # review the int type cast could have a nasty side effect, as it is behaving like a floor operation for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # review this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this: df[nodes] = 0 instead of the explicit loop. I am not 100% sure of the syntax but there is a way to write this without a loop. Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.4079904556274414 ms
exiting function "createEmptyDataFrame"
function call took 2.8250041007995605 ms
exiting function "cloneAndWriteProfiles"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    '''
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param linkConfig: The config link where all links are given.
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    '''

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption and usable battery percentages for load shifting.

    :param filePath: The relative file path to the input file
    :return:
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:E",
                              skiprows=0)
    scalar = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    scalarsOut = scalar.set_index('parameter')
    return scalarsOut

function call took 0.09800219535827637 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    inputRaw = pd.read_csv(filePath, header=4)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.09900045394897461 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    inputRaw = pd.read_csv(filePath, header=4)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.11198854446411133 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.08899927139282227 ms
exiting function "stringToBoolean"
function call took 0.2080097198486328 ms
exiting function "readInputBoolean"
function call took 0.41700029373168945 ms
exiting function "readVencoInput"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    '''
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param linkConfig: The config link where all links are given.
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    '''

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.05204653739929199 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    inputRaw = pd.read_csv(filePath, header=4)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.0789487361907959 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    inputRaw = pd.read_csv(filePath, header=4)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.10900020599365234 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.08199429512023926 ms
exiting function "stringToBoolean"
function call took 0.19599485397338867 ms
exiting function "readInputBoolean"
function call took 0.3379998207092285 ms
exiting function "readVencoInput"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    '''
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param linkConfig: The config link where all links are given.
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    '''

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.05203652381896973 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    inputRaw = pd.read_csv(filePath, header=4)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.08597350120544434 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    inputRaw = pd.read_csv(filePath, header=4)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.11396002769470215 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.08000373840332031 ms
exiting function "stringToBoolean"
function call took 0.19899868965148926 ms
exiting function "readInputBoolean"
function call took 0.34600329399108887 ms
exiting function "readVencoInput"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    '''
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param linkConfig: The config link where all links are given.
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    '''

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.06500005722045898 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    inputRaw = pd.read_csv(filePath, header=4)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.08700156211853027 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    inputRaw = pd.read_csv(filePath, header=4)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.11099553108215332 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.08100223541259766 ms
exiting function "stringToBoolean"
function call took 0.19699788093566895 ms
exiting function "readInputBoolean"
function call took 0.3649601936340332 ms
exiting function "readVencoInput"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    '''
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param linkConfig: The config link where all links are given.
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    '''

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.060999393463134766 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    inputRaw = pd.read_csv(filePath, header=4)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.08299827575683594 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    inputRaw = pd.read_csv(filePath, header=4)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.11699986457824707 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.08000040054321289 ms
exiting function "stringToBoolean"
function call took 0.20199966430664062 ms
exiting function "readInputBoolean"
function call took 0.35500049591064453 ms
exiting function "readVencoInput"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    '''
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param linkConfig: The config link where all links are given.
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    '''

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.06900978088378906 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return:
    """
    inputRaw = pd.read_csv(filePath, header=4)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.12401771545410156 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return:
    """
    inputRaw = pd.read_csv(filePath, header=4)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.14601588249206543 ms
exiting function "readInputCSV"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    '''
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param linkConfig: The config link where all links are given.
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    '''

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.05800366401672363 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return:
    """
    inputRaw = pd.read_csv(filePath, header=1)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    '''
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param linkConfig: The config link where all links are given.
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    '''

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.05400681495666504 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return:
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 205.90374398231506 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return:
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    '''
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param linkConfig: The config link where all links are given.
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    '''

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.0630040168762207 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return:
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 8.48477840423584 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return:
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.05896401405334473 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 5.560444593429565 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.11500716209411621 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.0820009708404541 ms
exiting function "stringToBoolean"
function call took 3.8463807106018066 ms
exiting function "readInputBoolean"
function call took 9.476878643035889 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.02600264549255371 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    return consumptionProfiles

entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.04399728775024414 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.06500077247619629 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.10100650787353516 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.0909876823425293 ms
exiting function "stringToBoolean"
function call took 0.1959991455078125 ms
exiting function "readInputBoolean"
function call took 0.3110010623931885 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.019997835159301758 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.04900002479553223 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :return: Returns scaled plugProfile in the same format as plugProfiles.

    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Panschluss', 'value'])
    return chargeProfiles

Error during call of function "calcChargeProfiles"
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\VencoPy\lib\site-packages\pandas\core\indexes\base.py", line 2897, in get_loc
    return self._engine.get_loc(key)
  File "pandas\_libs\index.pyx", line 107, in pandas._libs.index.IndexEngine.get_loc
  File "pandas\_libs\index.pyx", line 131, in pandas._libs.index.IndexEngine.get_loc
  File "pandas\_libs\hashtable_class_helper.pxi", line 1607, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas\_libs\hashtable_class_helper.pxi", line 1614, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'Panschluss'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\vencopy_repo\scripts\libLogging.py", line 32, in wrapper
    ret = f(*args, **kwargs)
  File "C:\vencopy_repo\scripts\libProfileCalculation.py", line 51, in calcChargeProfiles
    chargeProfiles = chargeProfiles * float(scalars.loc['Panschluss', 'value'])
  File "C:\ProgramData\Miniconda3\envs\VencoPy\lib\site-packages\pandas\core\indexing.py", line 1418, in __getitem__
    return self._getitem_tuple(key)
  File "C:\ProgramData\Miniconda3\envs\VencoPy\lib\site-packages\pandas\core\indexing.py", line 805, in _getitem_tuple
    return self._getitem_lowerdim(tup)
  File "C:\ProgramData\Miniconda3\envs\VencoPy\lib\site-packages\pandas\core\indexing.py", line 929, in _getitem_lowerdim
    section = self._getitem_axis(key, axis=i)
  File "C:\ProgramData\Miniconda3\envs\VencoPy\lib\site-packages\pandas\core\indexing.py", line 1850, in _getitem_axis
    return self._get_label(key, axis=axis)
  File "C:\ProgramData\Miniconda3\envs\VencoPy\lib\site-packages\pandas\core\indexing.py", line 160, in _get_label
    return self.obj._xs(label, axis=axis)
  File "C:\ProgramData\Miniconda3\envs\VencoPy\lib\site-packages\pandas\core\generic.py", line 3737, in xs
    loc = self.index.get_loc(key)
  File "C:\ProgramData\Miniconda3\envs\VencoPy\lib\site-packages\pandas\core\indexes\base.py", line 2899, in get_loc
    return self._engine.get_loc(self._maybe_cast_indexer(key))
  File "pandas\_libs\index.pyx", line 107, in pandas._libs.index.IndexEngine.get_loc
  File "pandas\_libs\index.pyx", line 131, in pandas._libs.index.IndexEngine.get_loc
  File "pandas\_libs\hashtable_class_helper.pxi", line 1607, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas\_libs\hashtable_class_helper.pxi", line 1614, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'Panschluss'
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.05500364303588867 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.07299232482910156 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.10799956321716309 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.07895898818969727 ms
exiting function "stringToBoolean"
function call took 0.19199919700622559 ms
exiting function "readInputBoolean"
function call took 0.3290364742279053 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.025034189224243164 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0009589195251464844 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.06996488571166992 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.039041757583618164 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 2.498959541320801 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.05400443077087402 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.1800062656402588 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['SoCmin', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['SoCmax', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

Error during call of function "calcChargeMinProfiles"
Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\VencoPy\lib\site-packages\pandas\core\indexes\base.py", line 2897, in get_loc
    return self._engine.get_loc(key)
  File "pandas\_libs\index.pyx", line 107, in pandas._libs.index.IndexEngine.get_loc
  File "pandas\_libs\index.pyx", line 131, in pandas._libs.index.IndexEngine.get_loc
  File "pandas\_libs\hashtable_class_helper.pxi", line 1607, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas\_libs\hashtable_class_helper.pxi", line 1614, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'SoCmin'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\vencopy_repo\scripts\libLogging.py", line 32, in wrapper
    ret = f(*args, **kwargs)
  File "C:\vencopy_repo\scripts\libProfileCalculation.py", line 212, in calcChargeMinProfiles
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['SoCmin', 'value']
  File "C:\ProgramData\Miniconda3\envs\VencoPy\lib\site-packages\pandas\core\indexing.py", line 1418, in __getitem__
    return self._getitem_tuple(key)
  File "C:\ProgramData\Miniconda3\envs\VencoPy\lib\site-packages\pandas\core\indexing.py", line 805, in _getitem_tuple
    return self._getitem_lowerdim(tup)
  File "C:\ProgramData\Miniconda3\envs\VencoPy\lib\site-packages\pandas\core\indexing.py", line 929, in _getitem_lowerdim
    section = self._getitem_axis(key, axis=i)
  File "C:\ProgramData\Miniconda3\envs\VencoPy\lib\site-packages\pandas\core\indexing.py", line 1850, in _getitem_axis
    return self._get_label(key, axis=axis)
  File "C:\ProgramData\Miniconda3\envs\VencoPy\lib\site-packages\pandas\core\indexing.py", line 160, in _get_label
    return self.obj._xs(label, axis=axis)
  File "C:\ProgramData\Miniconda3\envs\VencoPy\lib\site-packages\pandas\core\generic.py", line 3737, in xs
    loc = self.index.get_loc(key)
  File "C:\ProgramData\Miniconda3\envs\VencoPy\lib\site-packages\pandas\core\indexes\base.py", line 2899, in get_loc
    return self._engine.get_loc(self._maybe_cast_indexer(key))
  File "pandas\_libs\index.pyx", line 107, in pandas._libs.index.IndexEngine.get_loc
  File "pandas\_libs\index.pyx", line 131, in pandas._libs.index.IndexEngine.get_loc
  File "pandas\_libs\hashtable_class_helper.pxi", line 1607, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas\_libs\hashtable_class_helper.pxi", line 1614, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'SoCmin'
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.05399918556213379 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.0749979019165039 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.11896634101867676 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.10004186630249023 ms
exiting function "stringToBoolean"
function call took 0.22297000885009766 ms
exiting function "readInputBoolean"
function call took 0.3639688491821289 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.03199410438537598 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0010025501251220703 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.08999180793762207 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.03000020980834961 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 2.2209980487823486 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.05196404457092285 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.19396138191223145 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 2.926955223083496 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNumberProfiles"
source:
@logit
def createRandNumberProfiles(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles:
    :param setSeed:
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randProfiles = idxData.loc[:, 'randNo']
    return randProfiles

entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.06250548362731934 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.07814455032348633 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.12499475479125977 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.09376955032348633 ms
exiting function "stringToBoolean"
function call took 0.23439812660217285 ms
exiting function "readInputBoolean"
function call took 0.3906731605529785 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.031231403350830078 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.06250548362731934 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.03125357627868652 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 1.2813961505889893 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.03120875358581543 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.09373927116394043 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 1.2969787120819092 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.015624046325683594 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.10947585105895996 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.046788692474365234 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.06250357627868652 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.0781257152557373 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.10938501358032227 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

Error during call of function "normalizeProfiles"
Traceback (most recent call last):
  File "C:\vencopy_repo\scripts\libLogging.py", line 32, in wrapper
    ret = f(*args, **kwargs)
TypeError: normalizeProfiles() got an unexpected keyword argument 'normReference'
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.03125452995300293 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.06256389617919922 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.09372377395629883 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.09372353553771973 ms
exiting function "stringToBoolean"
function call took 0.18744730949401855 ms
exiting function "readInputBoolean"
function call took 0.2812657356262207 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.01566338539123535 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.04687643051147461 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.015581130981445312 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 0.9375486373901367 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.0312647819519043 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.09369921684265137 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 1.109381914138794 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.01560831069946289 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.07813382148742676 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.04683995246887207 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.046886444091796875 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.031238317489624023 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.04691672325134277 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

Error during call of function "normalizeProfiles"
Traceback (most recent call last):
  File "C:\vencopy_repo\scripts\libLogging.py", line 32, in wrapper
    ret = f(*args, **kwargs)
TypeError: normalizeProfiles() got an unexpected keyword argument 'normReference'
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.03128361701965332 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.06252408027648926 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.09373927116394043 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.07813000679016113 ms
exiting function "stringToBoolean"
function call took 0.17186927795410156 ms
exiting function "readInputBoolean"
function call took 0.26567697525024414 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.015594720840454102 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.06250572204589844 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.015611648559570312 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 0.9688420295715332 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.0156252384185791 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.0937643051147461 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 1.1563026905059814 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.015665769577026367 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.07808923721313477 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.03129768371582031 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.04687619209289551 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.03126025199890137 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.0468745231628418 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.0 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015671491622924805 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015566110610961914 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.04688596725463867 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.03124070167541504 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031214475631713867 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.04688382148742676 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "writeProfilesToCSV"
source:
@logit
def writeProfilesToCSV(config, listProfiles, singleFile=True, strAdd=''):
    """
    Function to write resulting aggregated and corrected VencoPy profiles to .csv files in the specified folder.

    :param config: VencoPy config file.
    :param listProfiles: List of DataFrames containing a VencoPy profile each to be written to a single file
    :return: None
    """

    profileNameList = ['uncontrolledCharging',
                       'electricityDemandDriving',
                       'SOCMax',
                       'SOCMin',
                       'gridConnection']

    length = {}
    data = []
    for iProf in listProfiles:
        data.append(iProf)
        length[iProf] = len(iProf)

    dataOut = pd.concat(data, axis=1)
    dataOut.columns = profileNameList

    if singleFile:
        dataOut.to_csv(config['linkOutput'] + 'vencoOutput_' + strAdd + '.csv')
    else:
        for iName, iProf in zip(profileNameList, listProfiles):
            iProf.to_csv(config['linkOutput'] + 'vencoOutput' + iName + strAdd + '.csv')

Error during call of function "writeProfilesToCSV"
Traceback (most recent call last):
  File "C:\vencopy_repo\scripts\libLogging.py", line 32, in wrapper
    ret = f(*args, **kwargs)
  File "C:\vencopy_repo\scripts\libOutput.py", line 120, in writeProfilesToCSV
    length[iProf] = len(iProf)
  File "C:\ProgramData\Miniconda3\envs\VencoPy\lib\site-packages\pandas\core\generic.py", line 1886, in __hash__
    " hashed".format(self.__class__.__name__)
TypeError: 'Series' objects are mutable, thus they cannot be hashed
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.0312960147857666 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.07810020446777344 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.07815337181091309 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.09372735023498535 ms
exiting function "stringToBoolean"
function call took 0.17188072204589844 ms
exiting function "readInputBoolean"
function call took 0.2812769412994385 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.01565718650817871 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.03126120567321777 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.031234025955200195 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 1.177098035812378 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.031260013580322266 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.1406385898590088 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 1.312567949295044 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.0312504768371582 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.10938024520874023 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.06250572204589844 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.04687356948852539 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.03126025199890137 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.04688429832458496 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.0 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015672683715820312 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015610456466674805 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.046871185302734375 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.04683995246887207 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.01566028594970703 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031253814697265625 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "writeProfilesToCSV"
source:
@logit
def writeProfilesToCSV(config, listProfiles, singleFile=True, strAdd=''):
    """
    Function to write resulting aggregated and corrected VencoPy profiles to .csv files in the specified folder.

    :param config: VencoPy config file.
    :param listProfiles: List of DataFrames containing a VencoPy profile each to be written to a single file
    :return: None
    """

    profileNameList = ['uncontrolledCharging',
                       'electricityDemandDriving',
                       'SOCMax',
                       'SOCMin',
                       'gridConnection']

    # length = {}
    data = []
    for iProf in listProfiles:
        data.append(iProf)
        # length[iProf] = len(iProf)

    dataOut = pd.concat(data, axis=1)
    dataOut.columns = profileNameList

    if singleFile:
        dataOut.to_csv(config['linkOutput'] + 'vencoOutput_' + strAdd + '.csv')
    else:
        for iName, iProf in zip(profileNameList, listProfiles):
            iProf.to_csv(config['linkOutput'] + 'vencoOutput' + iName + strAdd + '.csv')

Error during call of function "writeProfilesToCSV"
Traceback (most recent call last):
  File "C:\vencopy_repo\scripts\libLogging.py", line 32, in wrapper
    ret = f(*args, **kwargs)
  File "C:\vencopy_repo\scripts\libOutput.py", line 126, in writeProfilesToCSV
    dataOut.to_csv(config['linkOutput'] + 'vencoOutput_' + strAdd + '.csv')
KeyError: 'linkOutput'
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.046895503997802734 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.06249570846557617 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.0937337875366211 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.07813143730163574 ms
exiting function "stringToBoolean"
function call took 0.17186522483825684 ms
exiting function "readInputBoolean"
function call took 0.28125643730163574 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.015642642974853516 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.046834468841552734 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.015617847442626953 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 1.031285285949707 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.03125762939453125 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.07816743850708008 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 1.202970266342163 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.01566481590270996 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.07811880111694336 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.03127098083496094 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.031248092651367188 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.015619516372680664 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.04686594009399414 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.0 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015625953674316406 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015633821487426758 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031231164932250977 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.01562190055847168 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.015594482421875 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031215429306030273 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "writeProfilesToCSV"
source:
@logit
def writeProfilesToCSV(config, listProfiles, singleFile=True, strAdd=''):
    """
    Function to write resulting aggregated and corrected VencoPy profiles to .csv files in the specified folder.

    :param config: VencoPy config file.
    :param listProfiles: List of DataFrames containing a VencoPy profile each to be written to a single file
    :return: None
    """

    profileNameList = ['uncontrolledCharging',
                       'electricityDemandDriving',
                       'SOCMax',
                       'SOCMin',
                       'gridConnection']

    # length = {}
    data = []
    for iProf in listProfiles:
        data.append(iProf)
        # length[iProf] = len(iProf)

    dataOut = pd.concat(data, axis=1)
    dataOut.columns = profileNameList

    if singleFile:
        dataOut.to_csv(config['linkOutput'] + 'vencoOutput_' + strAdd + '.csv')
    else:
        for iName, iProf in zip(profileNameList, listProfiles):
            iProf.to_csv(config['linkOutput'] + 'vencoOutput' + iName + strAdd + '.csv')

function call took 0.015526533126831055 ms
exiting function "writeProfilesToCSV"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.468855381011963 ms
exiting function "createEmptyDataFrame"
function call took 2.8751368522644043 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.3906638622283936 ms
exiting function "createEmptyDataFrame"
function call took 2.78135085105896 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.37490177154541 ms
exiting function "createEmptyDataFrame"
function call took 2.7812981605529785 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.281372308731079 ms
exiting function "createEmptyDataFrame"
function call took 2.6407573223114014 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.6718661785125732 ms
exiting function "createEmptyDataFrame"
function call took 3.1250691413879395 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.04689669609069824 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.04681801795959473 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.07808375358581543 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.07814764976501465 ms
exiting function "stringToBoolean"
function call took 0.17189979553222656 ms
exiting function "readInputBoolean"
function call took 0.26561450958251953 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.01563405990600586 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.06249427795410156 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.015622615814208984 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 0.9688262939453125 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.031214237213134766 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.09379029273986816 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 1.109361171722412 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.0 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.06250476837158203 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.031238317489624023 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.046859025955200195 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.03126358985900879 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.046872854232788086 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.0 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.046866655349731445 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.03125643730163574 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.04683995246887207 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031246185302734375 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.0468752384185791 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.0625157356262207 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.07815337181091309 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.09372568130493164 ms
exiting function "stringToBoolean"
function call took 0.17187905311584473 ms
exiting function "readInputBoolean"
function call took 0.28127002716064453 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.015613794326782227 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.04688310623168945 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.015653610229492188 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 1.1718871593475342 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.031248092651367188 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.10943388938903809 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 1.2499420642852783 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.01563286781311035 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.07816147804260254 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.04685258865356445 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.07811403274536133 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.031248092651367188 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.04687952995300293 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.0 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.046877145767211914 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.03125262260437012 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.046878814697265625 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031250953674316406 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "writeProfilesToCSV"
source:
@logit
def writeProfilesToCSV(outputFolder, listProfiles, singleFile=True, strAdd=''):
    """
    Function to write resulting aggregated and corrected VencoPy profiles to .csv files in the specified folder.

    :param config: VencoPy config file.
    :param listProfiles: List of DataFrames containing a VencoPy profile each to be written to a single file
    :return: None
    """

    profileNameList = ['uncontrolledCharging',
                       'electricityDemandDriving',
                       'SOCMax',
                       'SOCMin',
                       'gridConnection']

    # length = {}
    data = []
    for iProf in listProfiles:
        data.append(iProf)
        # length[iProf] = len(iProf)

    dataOut = pd.concat(data, axis=1)
    dataOut.columns = profileNameList

    if singleFile:
        dataOut.to_csv(outputFolder + 'vencoOutput_' + strAdd + '.csv')
    else:
        for iName, iProf in zip(profileNameList, listProfiles):
            iProf.to_csv(outputFolder + 'vencoOutput' + iName + strAdd + '.csv')

function call took 0.0 ms
exiting function "writeProfilesToCSV"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.3282055854797363 ms
exiting function "createEmptyDataFrame"
function call took 2.718763589859009 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.078200101852417 ms
exiting function "createEmptyDataFrame"
function call took 2.4219906330108643 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.0625007152557373 ms
exiting function "createEmptyDataFrame"
function call took 2.406299114227295 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.093869686126709 ms
exiting function "createEmptyDataFrame"
function call took 2.422013521194458 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.0468993186950684 ms
exiting function "createEmptyDataFrame"
function call took 2.390650749206543 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.0624327659606934 ms
exiting function "createEmptyDataFrame"
function call took 2.406374931335449 ms
exiting function "cloneAndWriteProfiles"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.0468754768371582 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.06253743171691895 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.0781395435333252 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.06250524520874023 ms
exiting function "stringToBoolean"
function call took 0.17184925079345703 ms
exiting function "readInputBoolean"
function call took 0.2812621593475342 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.01563239097595215 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.04690861701965332 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.015636444091796875 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 0.9374849796295166 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.031293392181396484 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.09370923042297363 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 1.0936012268066406 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.0 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.06244802474975586 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.04693913459777832 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.04681849479675293 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.03125762939453125 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.031241178512573242 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.0 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015676498413085938 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.01557302474975586 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.04691314697265625 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.0312657356262207 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.04686999320983887 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031245708465576172 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "writeProfilesToCSV"
source:
@logit
def writeProfilesToCSV(outputFolder, listProfiles, singleFile=True, strAdd=''):
    """
    Function to write resulting aggregated and corrected VencoPy profiles to .csv files in the specified folder.

    :param config: VencoPy config file.
    :param listProfiles: List of DataFrames containing a VencoPy profile each to be written to a single file
    :return: None
    """

    profileNameList = ['uncontrolledCharging',
                       'electricityDemandDriving',
                       'SOCMax',
                       'SOCMin',
                       'gridConnection']

    # length = {}
    data = []
    for iProf in listProfiles:
        data.append(iProf)
        # length[iProf] = len(iProf)

    dataOut = pd.concat(data, axis=1)
    dataOut.columns = profileNameList

    if singleFile:
        dataOut.to_csv(outputFolder + 'vencoOutput_' + strAdd + '.csv')
    else:
        for iName, iProf in zip(profileNameList, listProfiles):
            iProf.to_csv(outputFolder + 'vencoOutput' + iName + strAdd + '.csv')

function call took 0.031157493591308594 ms
exiting function "writeProfilesToCSV"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.5156071186065674 ms
exiting function "createEmptyDataFrame"
function call took 2.906395196914673 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.125124931335449 ms
exiting function "createEmptyDataFrame"
function call took 2.4688401222229004 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.328183889389038 ms
exiting function "createEmptyDataFrame"
function call took 2.7031993865966797 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.18764066696167 ms
exiting function "createEmptyDataFrame"
function call took 2.546929359436035 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.3594157695770264 ms
exiting function "createEmptyDataFrame"
function call took 3.1563611030578613 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 3.6564266681671143 ms
exiting function "createEmptyDataFrame"
function call took 4.0782692432403564 ms
exiting function "cloneAndWriteProfiles"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.0625007152557373 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.09374761581420898 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.12500262260437012 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.07813024520874023 ms
exiting function "stringToBoolean"
function call took 0.2187504768371582 ms
exiting function "readInputBoolean"
function call took 0.3749988079071045 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.03125405311584473 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.04688072204589844 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.01560831069946289 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 1.281247854232788 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.04687809944152832 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.1562497615814209 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 1.6250507831573486 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.03119516372680664 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.07817435264587402 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.046833038330078125 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.06253480911254883 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.046834468841552734 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.0624997615814209 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.0 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015624761581420898 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015666484832763672 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.03126049041748047 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031235456466674805 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.04687643051147461 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031215429306030273 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "writeProfilesToCSV"
source:
@logit
def writeProfilesToCSV(outputFolder, listProfiles, singleFile=True, strAdd=''):
    """
    Function to write resulting aggregated and corrected VencoPy profiles to .csv files in the specified folder.

    :param config: VencoPy config file.
    :param listProfiles: List of DataFrames containing a VencoPy profile each to be written to a single file
    :return: None
    """

    profileNameList = ['uncontrolledCharging',
                       'electricityDemandDriving',
                       'SOCMax',
                       'SOCMin',
                       'gridConnection']

    # length = {}
    data = []
    for iProf in listProfiles:
        data.append(iProf)
        # length[iProf] = len(iProf)

    dataOut = pd.concat(data, axis=1)
    dataOut.columns = profileNameList

    if singleFile:
        dataOut.to_csv(outputFolder + 'vencoOutput' + strAdd + '.csv')
    else:
        for iName, iProf in zip(profileNameList, listProfiles):
            iProf.to_csv(outputFolder + 'vencoOutput_' + iName + strAdd + '.csv')

function call took 0.031230449676513672 ms
exiting function "writeProfilesToCSV"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.312542200088501 ms
exiting function "createEmptyDataFrame"
function call took 2.7499985694885254 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.562537670135498 ms
exiting function "createEmptyDataFrame"
function call took 2.921917200088501 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.0623180866241455 ms
exiting function "createEmptyDataFrame"
function call took 2.4062509536743164 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.0937423706054688 ms
exiting function "createEmptyDataFrame"
function call took 2.4531188011169434 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.32808518409729 ms
exiting function "createEmptyDataFrame"
function call took 2.703139066696167 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.312462329864502 ms
exiting function "createEmptyDataFrame"
function call took 2.7499513626098633 ms
exiting function "cloneAndWriteProfiles"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.031244993209838867 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.06250429153442383 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.10938048362731934 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.09373855590820312 ms
exiting function "stringToBoolean"
function call took 0.20311903953552246 ms
exiting function "readInputBoolean"
function call took 0.29686832427978516 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.03125476837158203 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.04692268371582031 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.015611886978149414 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 1.0624942779541016 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.03129267692565918 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.0937051773071289 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 1.2341768741607666 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.015625715255737305 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.07817411422729492 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.0312497615814209 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.046839237213134766 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.03127646446228027 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.04684805870056152 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.0 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015659332275390625 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031200885772705078 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031290531158447266 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031267642974853516 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.03119039535522461 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "writeProfilesToCSV"
source:
@logit
def writeProfilesToCSV(outputFolder, listProfiles, singleFile=True, strAdd=''):
    """
    Function to write resulting aggregated and corrected VencoPy profiles to .csv files in the specified folder.

    :param config: VencoPy config file.
    :param listProfiles: List of DataFrames containing a VencoPy profile each to be written to a single file
    :return: None
    """

    profileNameList = ['uncontrolledCharging',
                       'electricityDemandDriving',
                       'SOCMax',
                       'SOCMin',
                       'gridConnection']

    # length = {}
    data = []
    for iProf in listProfiles:
        data.append(iProf)
        # length[iProf] = len(iProf)

    dataOut = pd.concat(data, axis=1)
    dataOut.columns = profileNameList

    if singleFile:
        dataOut.to_csv(outputFolder + 'vencoOutput' + strAdd + '.csv')
    else:
        for iName, iProf in zip(profileNameList, listProfiles):
            iProf.to_csv(outputFolder + 'vencoOutput_' + iName + strAdd + '.csv')

function call took 0.0 ms
exiting function "writeProfilesToCSV"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.3750088214874268 ms
exiting function "createEmptyDataFrame"
function call took 2.7186880111694336 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.218778371810913 ms
exiting function "createEmptyDataFrame"
function call took 2.6718411445617676 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.8437507152557373 ms
exiting function "createEmptyDataFrame"
function call took 3.3437488079071045 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 3.0937838554382324 ms
exiting function "createEmptyDataFrame"
function call took 3.4531285762786865 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.0936496257781982 ms
exiting function "createEmptyDataFrame"
function call took 2.437530755996704 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.171872138977051 ms
exiting function "createEmptyDataFrame"
function call took 2.7031168937683105 ms
exiting function "cloneAndWriteProfiles"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.07807660102844238 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.10937356948852539 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.12499833106994629 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.07816815376281738 ms
exiting function "stringToBoolean"
function call took 0.20316648483276367 ms
exiting function "readInputBoolean"
function call took 0.39061665534973145 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.03121018409729004 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.06249427795410156 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.015620946884155273 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 2.046839714050293 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.04691576957702637 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.2343277931213379 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 2.4062564373016357 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 19.26557445526123 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.07814645767211914 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.07813668251037598 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.1093285083770752 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.03129076957702637 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.1405785083770752 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.0 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015627622604370117 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015665292739868164 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.06250309944152832 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.04687023162841797 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.04691028594970703 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.062465667724609375 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "writeProfilesToCSV"
source:
@logit
def writeProfilesToCSV(outputFolder, profileDictOut, singleFile=True, strAdd=''):
    """
    Function to write VencoPy profiles to either one or five .csv files in the output folder specified in outputFolder.

    :param outputFolder: Link to output folder
    :param profileDictOut: Dictionary with profile names in keys and profiles as pd.Series containing a VencoPy
    profile each to be written in value
    :param singleFile: If True, all profiles will be appended and written to one .csv file. If False, five files are
    written
    :param strAdd: String addition for filenames
    :return: None
    """

    if singleFile:
        data = []
        for iName, iProf in profileDictOut.items():
            data.append(iProf)
        dataOut = pd.concat(data, axis=1)
        dataOut.columns = profileDictOut.names()
        dataOut.to_csv(outputFolder + 'vencoOutput' + strAdd + '.csv')
    else:
        for iName, iProf in profileDictOut.items():
            iProf.to_csv(outputFolder + 'vencoOutput_' + iName + strAdd + '.csv')

entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.04687762260437012 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.06252646446228027 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.0937192440032959 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.09378671646118164 ms
exiting function "stringToBoolean"
function call took 0.18750596046447754 ms
exiting function "readInputBoolean"
function call took 0.31253743171691895 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.015591621398925781 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.03125619888305664 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.01562190055847168 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 1.0312232971191406 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.03129291534423828 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.10932397842407227 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 1.2812871932983398 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.01564931869506836 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.0781092643737793 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.046848297119140625 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.03129100799560547 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.031249046325683594 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.04682326316833496 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.0 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015665292739868164 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015647172927856445 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.04680585861206055 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.03125357627868652 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031246423721313477 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031252384185791016 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "writeProfilesToCSV"
source:
@logit
def writeProfilesToCSV(outputFolder, profileDictOut, singleFile=True, strAdd=''):
    """
    Function to write VencoPy profiles to either one or five .csv files in the output folder specified in outputFolder.

    :param outputFolder: Link to output folder
    :param profileDictOut: Dictionary with profile names in keys and profiles as pd.Series containing a VencoPy
    profile each to be written in value
    :param singleFile: If True, all profiles will be appended and written to one .csv file. If False, five files are
    written
    :param strAdd: String addition for filenames
    :return: None
    """

    if singleFile:
        dataOut = pd.DataFrame(profileDictOut)
        dataOut.to_csv(outputFolder + 'vencoOutput' + strAdd + '.csv')
    else:
        for iName, iProf in profileDictOut.items():
            iProf.to_csv(outputFolder + 'vencoOutput_' + iName + strAdd + '.csv')

function call took 0.0 ms
exiting function "writeProfilesToCSV"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.8906497955322266 ms
exiting function "createEmptyDataFrame"
function call took 3.328022003173828 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 3.843756675720215 ms
exiting function "createEmptyDataFrame"
function call took 4.265617847442627 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.281149387359619 ms
exiting function "createEmptyDataFrame"
function call took 2.84375262260437 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 3.4531302452087402 ms
exiting function "createEmptyDataFrame"
function call took 3.843750476837158 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.6718978881835938 ms
exiting function "createEmptyDataFrame"
function call took 3.0469088554382324 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.281252384185791 ms
exiting function "createEmptyDataFrame"
function call took 2.640629291534424 ms
exiting function "cloneAndWriteProfiles"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict_out = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkTSConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkTSREMix': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict_out

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.04682183265686035 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.06250262260437012 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.07812356948852539 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.07813048362731934 ms
exiting function "stringToBoolean"
function call took 0.15625405311584473 ms
exiting function "readInputBoolean"
function call took 0.2655785083770752 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.031243562698364258 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.04688072204589844 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.015659332275390625 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 1.1250004768371582 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.03125715255737305 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.0937492847442627 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 1.187408447265625 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.015661001205444336 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.0781397819519043 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.03126788139343262 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.06244659423828125 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.03123641014099121 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.06250166893005371 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.0 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.01563429832458496 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015633106231689453 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031229734420776367 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031307220458984375 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.04682159423828125 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.04687786102294922 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "writeProfilesToCSV"
source:
@logit
def writeProfilesToCSV(outputFolder, profileDictOut, singleFile=True, strAdd=''):
    """
    Function to write VencoPy profiles to either one or five .csv files in the output folder specified in outputFolder.

    :param outputFolder: Link to output folder
    :param profileDictOut: Dictionary with profile names in keys and profiles as pd.Series containing a VencoPy
    profile each to be written in value
    :param singleFile: If True, all profiles will be appended and written to one .csv file. If False, five files are
    written
    :param strAdd: String addition for filenames
    :return: None
    """

    if singleFile:
        dataOut = pd.DataFrame(profileDictOut)
        dataOut.to_csv(outputFolder + 'vencoOutput' + strAdd + '.csv')
    else:
        for iName, iProf in profileDictOut.items():
            iProf.to_csv(outputFolder + 'vencoOutput_' + iName + strAdd + '.csv')

function call took 0.015535593032836914 ms
exiting function "writeProfilesToCSV"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.5312423706054688 ms
exiting function "createEmptyDataFrame"
function call took 3.0312414169311523 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 4.4062488079071045 ms
exiting function "createEmptyDataFrame"
function call took 4.781245708465576 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 4.703019380569458 ms
exiting function "createEmptyDataFrame"
function call took 5.390623569488525 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 3.9218790531158447 ms
exiting function "createEmptyDataFrame"
function call took 4.312542915344238 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.500033140182495 ms
exiting function "createEmptyDataFrame"
function call took 2.9843332767486572 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, linkDict, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    dfProfile = pd.DataFrame(profile).iloc[:, 0]

    # initialize config
    cfg = yaml.load(open(linkDict['linkTSConfig']))
    linkRmx = linkDict['linkTSREMix']

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, cfg['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in cfg['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(linkRmx + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.562497615814209 ms
exiting function "createEmptyDataFrame"
function call took 3.0156590938568115 ms
exiting function "cloneAndWriteProfiles"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkOutputConfig': vencoConfig['linksRelative']['tsConfig'],
                    'linkOutputAnnual': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict

Error during call of function "initializeLinkMgr"
Traceback (most recent call last):
  File "C:\vencopy_repo\scripts\libLogging.py", line 32, in wrapper
    ret = f(*args, **kwargs)
  File "C:\vencopy_repo\scripts\libInput.py", line 38, in initializeLinkMgr
    'linkOutputConfig': vencoConfig['linksRelative']['tsConfig'],
KeyError: 'tsConfig'
Error during call of function "readVencoInput"
Traceback (most recent call last):
  File "C:\vencopy_repo\scripts\libLogging.py", line 32, in wrapper
    ret = f(*args, **kwargs)
  File "C:\vencopy_repo\scripts\libInput.py", line 121, in readVencoInput
    linkDict = initializeLinkMgr(config)
  File "C:\vencopy_repo\scripts\libLogging.py", line 35, in wrapper
    raise E
  File "C:\vencopy_repo\scripts\libLogging.py", line 32, in wrapper
    ret = f(*args, **kwargs)
  File "C:\vencopy_repo\scripts\libInput.py", line 38, in initializeLinkMgr
    'linkOutputConfig': vencoConfig['linksRelative']['tsConfig'],
KeyError: 'tsConfig'
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkOutputConfig': vencoConfig['linksRelative']['outputConfig'],
                    'linkOutputAnnual': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.07813048362731934 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.07811832427978516 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.12500500679016113 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.0781247615814209 ms
exiting function "stringToBoolean"
function call took 0.21875286102294922 ms
exiting function "readInputBoolean"
function call took 0.3750016689300537 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.03128409385681152 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.04687929153442383 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.015631437301635742 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 1.0780773162841797 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.03129982948303223 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.07814455032348633 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 1.1405186653137207 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.015674114227294922 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.07811784744262695 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.0468747615814209 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.03127169609069824 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.031187057495117188 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.04688143730163574 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.0 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.046814680099487305 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031275033950805664 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031222820281982422 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031250953674316406 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "writeProfilesToCSV"
source:
@logit
def writeProfilesToCSV(outputFolder, profileDictOut, singleFile=True, strAdd=''):
    """
    Function to write VencoPy profiles to either one or five .csv files in the output folder specified in outputFolder.

    :param outputFolder: Link to output folder
    :param profileDictOut: Dictionary with profile names in keys and profiles as pd.Series containing a VencoPy
    profile each to be written in value
    :param singleFile: If True, all profiles will be appended and written to one .csv file. If False, five files are
    written
    :param strAdd: String addition for filenames
    :return: None
    """

    if singleFile:
        dataOut = pd.DataFrame(profileDictOut)
        dataOut.to_csv(outputFolder + 'vencoOutput' + strAdd + '.csv')
    else:
        for iName, iProf in profileDictOut.items():
            iProf.to_csv(outputFolder + 'vencoOutput_' + iName + strAdd + '.csv')

function call took 0.015472412109375 ms
exiting function "writeProfilesToCSV"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, outputConfig['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in outputConfig['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(outputLink + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.109323263168335 ms
exiting function "createEmptyDataFrame"
function call took 2.4530701637268066 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, outputConfig['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in outputConfig['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(outputLink + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.3281404972076416 ms
exiting function "createEmptyDataFrame"
function call took 2.6719117164611816 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, outputConfig['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in outputConfig['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(outputLink + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.390625238418579 ms
exiting function "createEmptyDataFrame"
function call took 2.8281240463256836 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, outputConfig['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in outputConfig['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(outputLink + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.500000476837158 ms
exiting function "createEmptyDataFrame"
function call took 2.843785285949707 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, outputConfig['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in outputConfig['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(outputLink + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.203153610229492 ms
exiting function "createEmptyDataFrame"
function call took 2.5468738079071045 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profile: A VencoPy profile.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, outputConfig['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in outputConfig['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(outputLink + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.328087568283081 ms
exiting function "createEmptyDataFrame"
function call took 2.6874585151672363 ms
exiting function "cloneAndWriteProfiles"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkOutputConfig': vencoConfig['linksRelative']['outputConfig'],
                    'linkOutputAnnual': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.046883344650268555 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.06905722618103027 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.11590695381164551 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.12241959571838379 ms
exiting function "stringToBoolean"
function call took 0.2383265495300293 ms
exiting function "readInputBoolean"
function call took 0.36987972259521484 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.015625953674316406 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.053406476974487305 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.015621662139892578 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 1.0860490798950195 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.03731846809387207 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.09984397888183594 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 1.1492648124694824 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.015625953674316406 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.069061279296875 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.04686713218688965 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.03787398338317871 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.031208515167236328 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.03780984878540039 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.0 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015647172927856445 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.046888113021850586 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.037764549255371094 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.0312345027923584 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.03129267692565918 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "writeProfilesToCSV"
source:
@logit
def writeProfilesToCSV(outputFolder, profileDictOut, singleFile=True, strAdd=''):
    """
    Function to write VencoPy profiles to either one or five .csv files in the output folder specified in outputFolder.

    :param outputFolder: Link to output folder
    :param profileDictOut: Dictionary with profile names in keys and profiles as pd.Series containing a VencoPy
    profile each to be written in value
    :param singleFile: If True, all profiles will be appended and written to one .csv file. If False, five files are
    written
    :param strAdd: String addition for filenames
    :return: None
    """

    if singleFile:
        dataOut = pd.DataFrame(profileDictOut)
        dataOut.to_csv(outputFolder + 'vencoOutput' + strAdd + '.csv')
    else:
        for iName, iProf in profileDictOut.items():
            iProf.to_csv(outputFolder + 'vencoOutput_' + iName + strAdd + '.csv')

function call took 0.015586137771606445 ms
exiting function "writeProfilesToCSV"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkOutputConfig': vencoConfig['linksRelative']['outputConfig'],
                    'linkOutputAnnual': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.03778576850891113 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.07814288139343262 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.1003122329711914 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.0846712589263916 ms
exiting function "stringToBoolean"
function call took 0.20061135292053223 ms
exiting function "readInputBoolean"
function call took 0.316540002822876 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.022150516510009766 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.06250166893005371 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.022135019302368164 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 1.1816284656524658 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.053406476974487305 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.11593270301818848 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 1.385514259338379 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.015624046325683594 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.08471107482910156 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.05348467826843262 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.0937662124633789 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.03781890869140625 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.08465719223022461 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.0 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015625 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.053404808044433594 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.03125166893005371 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.04687333106994629 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.022150754928588867 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "writeProfilesToCSV"
source:
@logit
def writeProfilesToCSV(outputFolder, profileDictOut, singleFile=True, strAdd=''):
    """
    Function to write VencoPy profiles to either one or five .csv files in the output folder specified in outputFolder.

    :param outputFolder: Link to output folder
    :param profileDictOut: Dictionary with profile names in keys and profiles as pd.Series containing a VencoPy
    profile each to be written in value
    :param singleFile: If True, all profiles will be appended and written to one .csv file. If False, five files are
    written
    :param strAdd: String addition for filenames
    :return: None
    """

    if singleFile:
        dataOut = pd.DataFrame(profileDictOut)
        dataOut.to_csv(outputFolder + 'vencoOutput' + strAdd + '.csv')
    else:
        for iName, iProf in profileDictOut.items():
            iProf.to_csv(outputFolder + 'vencoOutput_' + iName + strAdd + '.csv')

function call took 0.01552271842956543 ms
exiting function "writeProfilesToCSV"
entering function "writeAnnualOutput"
source:
@logit
def writeAnnualOutput(profileDict, outputConfig, outputLink, noOfHoursOutput, technologyLabel, strAdd):
    """
    Output wrapper function to call cloneAndWriteProfiles once for each output profile.

    :param profileDict:
    :param outputConfig:
    :param outputLink:
    :param noOfHoursOutput:
    :param technologyLabel:
    :param filename:
    :param strAdd:
    :return: None
    """
    for iName, iProf in profileDict:
        filename = technologyLabel + '_' + iName + strAdd
        cloneAndWriteProfiles(iProf, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename)

Error during call of function "writeAnnualOutput"
Traceback (most recent call last):
  File "C:\vencopy_repo\scripts\libLogging.py", line 32, in wrapper
    ret = f(*args, **kwargs)
  File "C:\vencopy_repo\scripts\libOutput.py", line 31, in writeAnnualOutput
    for iName, iProf in profileDict:
ValueError: too many values to unpack (expected 2)
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkOutputConfig': vencoConfig['linksRelative']['outputConfig'],
                    'linkOutputAnnual': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.03126788139343262 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.08464860916137695 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.10031676292419434 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.08463263511657715 ms
exiting function "stringToBoolean"
function call took 0.20060491561889648 ms
exiting function "readInputBoolean"
function call took 0.31652140617370605 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.015637636184692383 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.031249046325683594 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.02222442626953125 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 1.1486320495605469 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.04686856269836426 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.10679745674133301 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 1.1653892993927002 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.01562047004699707 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.06913280487060547 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.037764549255371094 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.0781400203704834 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.022227764129638672 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.046898603439331055 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.0 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015624046325683594 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol:
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    # review general could the filterCons and critCol not be hardcoded or sotred in a hidden data structure,
    # so that it has not to be passed directly between functions? A class could achieve this goal
    # easily (providing a hidden data structure in the shape of an attribute) making the code more structured?
    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015624523162841797 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.03777432441711426 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031250953674316406 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.03128767013549805 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.022186756134033203 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "writeProfilesToCSV"
source:
@logit
def writeProfilesToCSV(outputFolder, profileDictOut, singleFile=True, strAdd=''):
    """
    Function to write VencoPy profiles to either one or five .csv files in the output folder specified in outputFolder.

    :param outputFolder: Link to output folder
    :param profileDictOut: Dictionary with profile names in keys and profiles as pd.Series containing a VencoPy
    profile each to be written in value
    :param singleFile: If True, all profiles will be appended and written to one .csv file. If False, five files are
    written
    :param strAdd: String addition for filenames
    :return: None
    """

    if singleFile:
        dataOut = pd.DataFrame(profileDictOut)
        dataOut.to_csv(outputFolder + 'vencoOutput' + strAdd + '.csv')
    else:
        for iName, iProf in profileDictOut.items():
            iProf.to_csv(outputFolder + 'vencoOutput_' + iName + strAdd + '.csv')

function call took 0.01542353630065918 ms
exiting function "writeProfilesToCSV"
entering function "writeAnnualOutput"
source:
@logit
def writeAnnualOutput(profileDict, outputConfig, outputLink, noOfHoursOutput, technologyLabel, strAdd):
    """
    Output wrapper function to call cloneAndWriteProfiles once for each output profile.

    :param profileDict:
    :param outputConfig:
    :param outputLink:
    :param noOfHoursOutput:
    :param technologyLabel:
    :param filename:
    :param strAdd:
    :return: None
    """
    for iName, iProf in profileDict.items():
        filename = technologyLabel + '_' + iName + strAdd
        cloneAndWriteProfiles(iProf, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename)

entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profileDict: A dictionary holding five VencoPy profiles as Series including their names as keys.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, outputConfig['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in outputConfig['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(outputLink + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.1744449138641357 ms
exiting function "createEmptyDataFrame"
function call took 2.5538034439086914 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profileDict: A dictionary holding five VencoPy profiles as Series including their names as keys.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, outputConfig['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in outputConfig['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(outputLink + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.258981466293335 ms
exiting function "createEmptyDataFrame"
function call took 2.5911693572998047 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profileDict: A dictionary holding five VencoPy profiles as Series including their names as keys.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, outputConfig['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in outputConfig['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(outputLink + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.1906559467315674 ms
exiting function "createEmptyDataFrame"
function call took 2.5600926876068115 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profileDict: A dictionary holding five VencoPy profiles as Series including their names as keys.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, outputConfig['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in outputConfig['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(outputLink + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.2907443046569824 ms
exiting function "createEmptyDataFrame"
function call took 2.654237985610962 ms
exiting function "cloneAndWriteProfiles"
entering function "cloneAndWriteProfiles"
source:
@logit
def cloneAndWriteProfiles(profile, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profileDict: A dictionary holding five VencoPy profiles as Series including their names as keys.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, outputConfig['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in outputConfig['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(outputLink + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.227440118789673 ms
exiting function "createEmptyDataFrame"
function call took 2.575296640396118 ms
exiting function "cloneAndWriteProfiles"
function call took 12.934600114822388 ms
exiting function "writeAnnualOutput"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkOutputConfig': vencoConfig['linksRelative']['outputConfig'],
                    'linkOutputAnnual': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.046833038330078125 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.06250309944152832 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.09375119209289551 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.07812142372131348 ms
exiting function "stringToBoolean"
function call took 0.17187261581420898 ms
exiting function "readInputBoolean"
function call took 0.28120875358581543 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.03129720687866211 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.04687643051147461 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.015582799911499023 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 0.9375011920928955 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.03130626678466797 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.09372210502624512 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 1.0936994552612305 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.015623807907104492 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.07811880111694336 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.046880483627319336 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.03121352195739746 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.03129243850708008 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.04687142372131348 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.0 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.01562356948852539 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.04686594009399414 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.0312654972076416 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.03123331069946289 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.03122687339782715 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "writeProfilesToCSV"
source:
@logit
def writeProfilesToCSV(outputFolder, profileDictOut, singleFile=True, strAdd=''):
    """
    Function to write VencoPy profiles to either one or five .csv files in the output folder specified in outputFolder.

    :param outputFolder: Link to output folder
    :param profileDictOut: Dictionary with profile names in keys and profiles as pd.Series containing a VencoPy
    profile each to be written in value
    :param singleFile: If True, all profiles will be appended and written to one .csv file. If False, five files are
    written
    :param strAdd: String addition for filenames
    :return: None
    """

    if singleFile:
        dataOut = pd.DataFrame(profileDictOut)
        dataOut.to_csv(outputFolder + 'vencoOutput' + strAdd + '.csv')
    else:
        for iName, iProf in profileDictOut.items():
            iProf.to_csv(outputFolder + 'vencoOutput_' + iName + strAdd + '.csv')

function call took 0.015513896942138672 ms
exiting function "writeProfilesToCSV"
entering function "writeAnnualOutputForREMix"
source:
@logit
def writeAnnualOutputForREMix(profileDict, outputConfig, outputLink, noOfHoursOutput, technologyLabel, strAdd):
    """
    Output wrapper function to call cloneAndWriteProfile once for each output profile.

    :param profileDict: Dictionary holding profile names and profiles in pd.Series to be cloned and written
    :param outputConfig: REMix specific configuration file holding model nodes
    :param outputLink: link to output folder
    :param noOfHoursOutput: Integer describing the number of hours that the profiles are cloned to
    :param technologyLabel: String holding a REMix eCarsDtl technology label
    :param strAdd: String addition for output writing
    :return: None
    """
    for iName, iProf in profileDict.items():
        filename = technologyLabel + '_' + iName + strAdd
        cloneAndWriteProfile(iProf, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename)

entering function "cloneAndWriteProfile"
source:
@logit
def cloneAndWriteProfile(profile, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profileDict: A dictionary holding five VencoPy profiles as Series including their names as keys.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, outputConfig['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in outputConfig['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(outputLink + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.093594551086426 ms
exiting function "createEmptyDataFrame"
function call took 2.4531359672546387 ms
exiting function "cloneAndWriteProfile"
entering function "cloneAndWriteProfile"
source:
@logit
def cloneAndWriteProfile(profile, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profileDict: A dictionary holding five VencoPy profiles as Series including their names as keys.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, outputConfig['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in outputConfig['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(outputLink + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.078174114227295 ms
exiting function "createEmptyDataFrame"
function call took 2.421902894973755 ms
exiting function "cloneAndWriteProfile"
entering function "cloneAndWriteProfile"
source:
@logit
def cloneAndWriteProfile(profile, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profileDict: A dictionary holding five VencoPy profiles as Series including their names as keys.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, outputConfig['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in outputConfig['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(outputLink + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.0625059604644775 ms
exiting function "createEmptyDataFrame"
function call took 2.3905930519104004 ms
exiting function "cloneAndWriteProfile"
entering function "cloneAndWriteProfile"
source:
@logit
def cloneAndWriteProfile(profile, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profileDict: A dictionary holding five VencoPy profiles as Series including their names as keys.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, outputConfig['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in outputConfig['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(outputLink + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.0781233310699463 ms
exiting function "createEmptyDataFrame"
function call took 2.40624737739563 ms
exiting function "cloneAndWriteProfile"
entering function "cloneAndWriteProfile"
source:
@logit
def cloneAndWriteProfile(profile, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profileDict: A dictionary holding five VencoPy profiles as Series including their names as keys.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, outputConfig['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in outputConfig['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(outputLink + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.0625102519989014 ms
exiting function "createEmptyDataFrame"
function call took 2.4062492847442627 ms
exiting function "cloneAndWriteProfile"
entering function "cloneAndWriteProfile"
source:
@logit
def cloneAndWriteProfile(profile, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profileDict: A dictionary holding five VencoPy profiles as Series including their names as keys.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, outputConfig['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in outputConfig['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(outputLink + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.2031731605529785 ms
exiting function "createEmptyDataFrame"
function call took 2.5312864780426025 ms
exiting function "cloneAndWriteProfile"
function call took 14.609415054321289 ms
exiting function "writeAnnualOutputForREMix"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkOutputConfig': vencoConfig['linksRelative']['outputConfig'],
                    'linkOutputAnnual': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.03126406669616699 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.06253552436828613 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.07808876037597656 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.07811546325683594 ms
exiting function "stringToBoolean"
function call took 0.1562042236328125 ms
exiting function "readInputBoolean"
function call took 0.2656223773956299 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.015593528747558594 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.04687309265136719 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.015619039535522461 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 0.937542200088501 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.03127336502075195 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.09372448921203613 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 1.2498714923858643 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.015622377395629883 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.10932660102844238 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.046929121017456055 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.0468449592590332 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.031223773956298828 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.04688382148742676 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.0 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015663862228393555 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015583992004394531 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.04687380790710449 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.03128957748413086 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.046869516372680664 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031212806701660156 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "writeProfilesToCSV"
source:
@logit
def writeProfilesToCSV(outputFolder, profileDictOut, singleFile=True, strAdd=''):
    """
    Function to write VencoPy profiles to either one or five .csv files in the output folder specified in outputFolder.

    :param outputFolder: Link to output folder
    :param profileDictOut: Dictionary with profile names in keys and profiles as pd.Series containing a VencoPy
    profile each to be written in value
    :param singleFile: If True, all profiles will be appended and written to one .csv file. If False, five files are
    written
    :param strAdd: String addition for filenames
    :return: None
    """

    if singleFile:
        dataOut = pd.DataFrame(profileDictOut)
        dataOut.to_csv(outputFolder + 'vencoOutput' + strAdd + '.csv')
    else:
        for iName, iProf in profileDictOut.items():
            iProf.to_csv(outputFolder + 'vencoOutput_' + iName + strAdd + '.csv')

function call took 0.015661954879760742 ms
exiting function "writeProfilesToCSV"
entering function "writeAnnualOutputForREMix"
source:
@logit
def writeAnnualOutputForREMix(profileDict, outputConfig, outputLink, noOfHoursOutput, technologyLabel, strAdd):
    """
    Output wrapper function to call cloneAndWriteProfile once for each output profile.

    :param profileDict: Dictionary holding profile names and profiles in pd.Series to be cloned and written
    :param outputConfig: REMix specific configuration file holding model nodes
    :param outputLink: link to output folder
    :param noOfHoursOutput: Integer describing the number of hours that the profiles are cloned to
    :param technologyLabel: String holding a REMix eCarsDtl technology label
    :param strAdd: String addition for output writing
    :return: None
    """
    for iName, iProf in profileDict.items():
        filename = technologyLabel + '_' + iName + strAdd
        cloneAndWriteProfile(iProf, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename)

entering function "cloneAndWriteProfile"
source:
@logit
def cloneAndWriteProfile(profile, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profileDict: A dictionary holding five VencoPy profiles as Series including their names as keys.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, outputConfig['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in outputConfig['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(outputLink + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.2812933921813965 ms
exiting function "createEmptyDataFrame"
function call took 2.625009059906006 ms
exiting function "cloneAndWriteProfile"
entering function "cloneAndWriteProfile"
source:
@logit
def cloneAndWriteProfile(profile, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profileDict: A dictionary holding five VencoPy profiles as Series including their names as keys.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, outputConfig['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in outputConfig['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(outputLink + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.1405751705169678 ms
exiting function "createEmptyDataFrame"
function call took 2.4843411445617676 ms
exiting function "cloneAndWriteProfile"
entering function "cloneAndWriteProfile"
source:
@logit
def cloneAndWriteProfile(profile, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profileDict: A dictionary holding five VencoPy profiles as Series including their names as keys.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, outputConfig['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in outputConfig['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(outputLink + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.07818341255188 ms
exiting function "createEmptyDataFrame"
function call took 2.406249523162842 ms
exiting function "cloneAndWriteProfile"
entering function "cloneAndWriteProfile"
source:
@logit
def cloneAndWriteProfile(profile, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profileDict: A dictionary holding five VencoPy profiles as Series including their names as keys.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, outputConfig['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in outputConfig['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(outputLink + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 3.0780835151672363 ms
exiting function "createEmptyDataFrame"
function call took 3.4531688690185547 ms
exiting function "cloneAndWriteProfile"
entering function "cloneAndWriteProfile"
source:
@logit
def cloneAndWriteProfile(profile, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profileDict: A dictionary holding five VencoPy profiles as Series including their names as keys.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, outputConfig['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in outputConfig['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(outputLink + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.40625 ms
exiting function "createEmptyDataFrame"
function call took 2.765582323074341 ms
exiting function "cloneAndWriteProfile"
entering function "cloneAndWriteProfile"
source:
@logit
def cloneAndWriteProfile(profile, outputConfig, outputLink, noOfHoursOutput, technologyLabel, filename):
    """
    This action clones daily profiles to cover the specified time horizon given in noOfHoursOutput.

    :param profileDict: A dictionary holding five VencoPy profiles as Series including their names as keys.
    :param linkDict: A VencoPy link dictionary.
    :param noOfHoursOutput: Number of hours to clone the daily profile to (for 1 (non-gap-)year set to 8760)
    :param technologyLabel: Technology (e.g. vehicle segment "BEV-S") label for the filename that is written.
    :param filename: Name of the file to be written.
    :return: None.
    """

    df = createEmptyDataFrame(technologyLabel, noOfHoursOutput, outputConfig['Nodes'])
    # review is this correct? What happens when noOfHoursOutput/len(profile) is smaller then 0? Then noOfClones
    # would be negative and I am not sure if this would be coerced to 0 by the following int type cast later on.
    # Is this handled upstream in the call chain?
    noOfClones = noOfHoursOutput / len(profile) - 1

    # FixMe the int type cast could have a nasty side effect, as it is behaving like a floor operation
    # for the float division above. Is this intended?
    profileCloned = profile.append([profile] * int(noOfClones), ignore_index=True)

    if len(profileCloned) < noOfHoursOutput:
        subHours = noOfHoursOutput - len(profileCloned)
        profileCloned = profileCloned.append(profile[range(subHours)], ignore_index=True)

    # FixMe this .copy() seems to be redundant if createEmptyDataFrame above indeed creates a fresh new empty
    # dataframe. Am I missing something here?
    profilesOut = df.copy()
    for i in outputConfig['NonNullNodes']:
        profilesOut.loc[:, i] = np.round(profileCloned, 3)

    profilesOut.to_csv(outputLink + '/' + filename + '.csv', index=False)

entering function "createEmptyDataFrame"
source:
@logit
def createEmptyDataFrame(technologyLabel, numberOfHours, nodes):
    """
    Creation method for building a specifically formatted dataframe for output processing of VencoPy profiles.

    :param technologyLabel: String for an index column
    :param numberOfHours: Length of resulting dataframe
    :param nodes: Number of columns of resultung dataframe
    :return: Empty dataframe with the technologyLabel as values in the first column, number of rows as specified by
    numberOfHours. Nodes gives number of value columns.
    """

    df = pd.concat([pd.DataFrame([i], columns=['']) for i in range(1, numberOfHours + 1)], ignore_index=True)
    df[' '] = technologyLabel  # Add technology column
    df = df[[' ', '']]  # Re-arrange columns order

    # review if nodes is a list of column labels then one could also write it like this:
    # df[nodes] = 0 instead of the explicit loop.
    # I am not 100% sure of the syntax but there is a way to write this without a loop.
    # Should be detailed in pandas indexing docu
    for i in nodes:
        df[i] = 0

    s = df[''] < 10
    s1 = (df[''] >= 10) & (df[''] < 100)
    s2 = (df[''] >= 100) & (df[''] < 1000)
    s3 = df[''] >= 1000

    # review: there exists the python string formatting mini language which provides padding of strings (also leading).
    # see here: https://docs.python.org/3.4/library/string.html#format-specification-mini-language
    #  I think with a format string of the shape 't'+'{0:0<4.0d}'.format(x) would result for all four lines below in
    #  the correct output. Then also lines 894 to 897 would be superfluous.

    df.loc[s, ''] = df.loc[s, ''].apply(lambda x: "{}{}".format('t000', x))
    df.loc[s1, ''] = df.loc[s1, ''].apply(lambda x: "{}{}".format('t00', x))
    df.loc[s2, ''] = df.loc[s2, ''].apply(lambda x: "{}{}".format('t0', x))
    df.loc[s3, ''] = df.loc[s3, ''].apply(lambda x: "{}{}".format('t', x))
    return df

function call took 2.2969117164611816 ms
exiting function "createEmptyDataFrame"
function call took 2.625033140182495 ms
exiting function "cloneAndWriteProfile"
function call took 16.37499475479126 ms
exiting function "writeAnnualOutputForREMix"
entering function "linePlot"
source:
@logit
def linePlot(profileDict, linkOutput, show=True, write=True, stradd=''):
    fig, ax = plt.subplots()
    for iKey, iVal in profileDict.items():
        sns.lineplot(iVal.index.levels, iVal, label=iKey)
    ax.set_xlabel('Hour')
    ax.set_ylabel('Normalized profiles')
    ax.legend(loc='upper center', ncol=len(profileDict.keys()), bbox_to_anchor=(0.5, 1.1))
    fn = os.path.join(linkOutput, stradd + '.png')
    if show: plt.show()
    if write: fig.savefig(fn)

Error during call of function "linePlot"
Traceback (most recent call last):
  File "C:\vencopy_repo\scripts\libLogging.py", line 32, in wrapper
    ret = f(*args, **kwargs)
  File "C:\vencopy_repo\scripts\libOutput.py", line 187, in linePlot
    sns.lineplot(iVal.index.levels, iVal, label=iKey)
AttributeError: 'Index' object has no attribute 'levels'
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkOutputConfig': vencoConfig['linksRelative']['outputConfig'],
                    'linkOutputAnnual': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.0468440055847168 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.06250452995300293 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.09378695487976074 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.07808446884155273 ms
exiting function "stringToBoolean"
function call took 0.17187142372131348 ms
exiting function "readInputBoolean"
function call took 0.29683470726013184 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.031265974044799805 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.06253218650817871 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.0312044620513916 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 1.843764305114746 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.046913862228393555 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.15622162818908691 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 2.296764850616455 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.015661001205444336 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.07812380790710449 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.06246662139892578 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.07812380790710449 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.03125739097595215 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.06254076957702637 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.0 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015647172927856445 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.0468134880065918 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.03125572204589844 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031287431716918945 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031246662139892578 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "writeProfilesToCSV"
source:
@logit
def writeProfilesToCSV(outputFolder, profileDictOut, singleFile=True, strAdd=''):
    """
    Function to write VencoPy profiles to either one or five .csv files in the output folder specified in outputFolder.

    :param outputFolder: Link to output folder
    :param profileDictOut: Dictionary with profile names in keys and profiles as pd.Series containing a VencoPy
    profile each to be written in value
    :param singleFile: If True, all profiles will be appended and written to one .csv file. If False, five files are
    written
    :param strAdd: String addition for filenames
    :return: None
    """

    if singleFile:
        dataOut = pd.DataFrame(profileDictOut)
        dataOut.to_csv(outputFolder + 'vencoOutput' + strAdd + '.csv')
    else:
        for iName, iProf in profileDictOut.items():
            iProf.to_csv(outputFolder + 'vencoOutput_' + iName + strAdd + '.csv')

function call took 0.04678177833557129 ms
exiting function "writeProfilesToCSV"
entering function "linePlot"
source:
@logit
def linePlot(profileDict, linkOutput, show=True, write=True, stradd=''):
    fig, ax = plt.subplots()
    for iKey, iVal in profileDict.items():
        sns.lineplot(iVal.index.levels, iVal, label=iKey)
    ax.set_xlabel('Hour')
    ax.set_ylabel('Normalized profiles')
    ax.legend(loc='upper center', ncol=len(profileDict.keys()), bbox_to_anchor=(0.5, 1.1))
    fn = os.path.join(linkOutput, stradd + '.png')
    if show: plt.show()
    if write: fig.savefig(fn)

entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkOutputConfig': vencoConfig['linksRelative']['outputConfig'],
                    'linkOutputAnnual': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.046875953674316406 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.0625007152557373 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.09374451637268066 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.09376096725463867 ms
exiting function "stringToBoolean"
function call took 0.18750548362731934 ms
exiting function "readInputBoolean"
function call took 0.29688215255737305 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.031280517578125 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.046889543533325195 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.031194210052490234 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 1.1406309604644775 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.03125190734863281 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.07811856269836426 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 1.078073501586914 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.015576601028442383 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.06253385543823242 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.031296730041503906 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.04684758186340332 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.015620231628417969 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.04690361022949219 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.0 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015625715255737305 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015622377395629883 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.046836137771606445 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.03128314018249512 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.03121328353881836 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.015669822692871094 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "writeProfilesToCSV"
source:
@logit
def writeProfilesToCSV(outputFolder, profileDictOut, singleFile=True, strAdd=''):
    """
    Function to write VencoPy profiles to either one or five .csv files in the output folder specified in outputFolder.

    :param outputFolder: Link to output folder
    :param profileDictOut: Dictionary with profile names in keys and profiles as pd.Series containing a VencoPy
    profile each to be written in value
    :param singleFile: If True, all profiles will be appended and written to one .csv file. If False, five files are
    written
    :param strAdd: String addition for filenames
    :return: None
    """

    if singleFile:
        dataOut = pd.DataFrame(profileDictOut)
        dataOut.to_csv(outputFolder + 'vencoOutput' + strAdd + '.csv')
    else:
        for iName, iProf in profileDictOut.items():
            iProf.to_csv(outputFolder + 'vencoOutput_' + iName + strAdd + '.csv')

function call took 0.031281471252441406 ms
exiting function "writeProfilesToCSV"
entering function "linePlot"
source:
@logit
def linePlot(profileDict, linkOutput, show=True, write=True, stradd=''):
    fig, ax = plt.subplots()
    for iKey, iVal in profileDict.items():
        sns.lineplot(iVal.index.levels, iVal, label=iKey)
    ax.set_xlabel('Hour')
    ax.set_ylabel('Normalized profiles')
    ax.legend(loc='upper center', ncol=len(profileDict.keys()), bbox_to_anchor=(0.5, 1.1))
    fn = os.path.join(linkOutput, stradd + '.png')
    if show: plt.show()
    if write: fig.savefig(fn)

Error during call of function "linePlot"
Traceback (most recent call last):
  File "C:\vencopy_repo\scripts\libLogging.py", line 32, in wrapper
    ret = f(*args, **kwargs)
  File "C:\vencopy_repo\scripts\libOutput.py", line 187, in linePlot
    sns.lineplot(iVal.index.levels, iVal, label=iKey)
AttributeError: 'Index' object has no attribute 'levels'
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkOutputConfig': vencoConfig['linksRelative']['outputConfig'],
                    'linkOutputAnnual': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.03125262260437012 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.06254696846008301 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.09370040893554688 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.07813334465026855 ms
exiting function "stringToBoolean"
function call took 0.17183375358581543 ms
exiting function "readInputBoolean"
function call took 0.26563334465026855 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.015633344650268555 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.046857595443725586 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.015631437301635742 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 0.9375026226043701 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.03130078315734863 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.07809185981750488 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 1.1092205047607422 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.0 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.06253600120544434 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.04684305191040039 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.04686570167541504 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.031256675720214844 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.03128647804260254 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.0 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015580892562866211 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015622138977050781 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.03128552436828613 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.04684329032897949 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031288862228393555 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.03125572204589844 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "writeProfilesToCSV"
source:
@logit
def writeProfilesToCSV(outputFolder, profileDictOut, singleFile=True, strAdd=''):
    """
    Function to write VencoPy profiles to either one or five .csv files in the output folder specified in outputFolder.

    :param outputFolder: Link to output folder
    :param profileDictOut: Dictionary with profile names in keys and profiles as pd.Series containing a VencoPy
    profile each to be written in value
    :param singleFile: If True, all profiles will be appended and written to one .csv file. If False, five files are
    written
    :param strAdd: String addition for filenames
    :return: None
    """

    if singleFile:
        dataOut = pd.DataFrame(profileDictOut)
        dataOut.to_csv(outputFolder + 'vencoOutput' + strAdd + '.csv')
    else:
        for iName, iProf in profileDictOut.items():
            iProf.to_csv(outputFolder + 'vencoOutput_' + iName + strAdd + '.csv')

function call took 0.015528202056884766 ms
exiting function "writeProfilesToCSV"
entering function "linePlot"
source:
@logit
def linePlot(profileDict, linkOutput, show=True, write=True, stradd=''):
    fig, ax = plt.subplots()
    for iKey, iVal in profileDict.items():
        sns.lineplot(iVal.index, iVal, label=iKey)
    ax.set_xlabel('Hour')
    ax.set_ylabel('Normalized profiles')
    ax.legend(loc='upper center', ncol=len(profileDict.keys()), bbox_to_anchor=(0.5, 1.1))
    fn = os.path.join(linkOutput, stradd + '.png')
    if show: plt.show()
    if write: fig.savefig(fn)

function call took 20.086153507232666 ms
exiting function "linePlot"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkOutputConfig': vencoConfig['linksRelative']['outputConfig'],
                    'linkOutputAnnual': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.04687762260437012 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.062453508377075195 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.09375333786010742 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.07809090614318848 ms
exiting function "stringToBoolean"
function call took 0.1875143051147461 ms
exiting function "readInputBoolean"
function call took 0.31247472763061523 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.015624523162841797 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.06253576278686523 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.04687643051147461 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 1.8749597072601318 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.04688429832458496 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.14063572883605957 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 2.281057596206665 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.015618562698364258 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.0937964916229248 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.062499046325683594 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.09375786781311035 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.03119516372680664 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.07812666893005371 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.0 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015623331069946289 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015639543533325195 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.046863555908203125 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.04692482948303223 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.031212806701660156 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.04689788818359375 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.015628814697265625 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "writeProfilesToCSV"
source:
@logit
def writeProfilesToCSV(outputFolder, profileDictOut, singleFile=True, strAdd=''):
    """
    Function to write VencoPy profiles to either one or five .csv files in the output folder specified in outputFolder.

    :param outputFolder: Link to output folder
    :param profileDictOut: Dictionary with profile names in keys and profiles as pd.Series containing a VencoPy
    profile each to be written in value
    :param singleFile: If True, all profiles will be appended and written to one .csv file. If False, five files are
    written
    :param strAdd: String addition for filenames
    :return: None
    """

    if singleFile:
        dataOut = pd.DataFrame(profileDictOut)
        dataOut.to_csv(outputFolder + 'vencoOutput' + strAdd + '.csv')
    else:
        for iName, iProf in profileDictOut.items():
            iProf.to_csv(outputFolder + 'vencoOutput_' + iName + strAdd + '.csv')

function call took 0.04689145088195801 ms
exiting function "writeProfilesToCSV"
entering function "linePlot"
source:
@logit
def linePlot(profileDict, linkOutput, show=True, write=True, stradd=''):
    fig, ax = plt.subplots()
    for iKey, iVal in profileDict.items():
        sns.lineplot(iVal.index, iVal, label=iKey)
    ax.set_xlabel('Hour')
    ax.set_ylabel('Normalized profiles')
    ax.legend(loc='upper center', ncol=len(profileDict.keys()), bbox_to_anchor=(0.5, 1.1))
    fn = os.path.join(linkOutput, stradd + '.png')
    if show: plt.show()
    if write: fig.savefig(fn)

entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkOutputConfig': vencoConfig['linksRelative']['outputConfig'],
                    'linkOutputAnnual': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.07202363014221191 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.09383487701416016 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.14895415306091309 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.10950613021850586 ms
exiting function "stringToBoolean"
function call took 0.25846028327941895 ms
exiting function "readInputBoolean"
function call took 0.4366602897644043 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.03600621223449707 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.06898951530456543 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.018198251724243164 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 1.0140061378479004 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.033615827560424805 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.08617663383483887 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 1.1909153461456299 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.016498804092407227 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.06775236129760742 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.048857688903808594 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.03640246391296387 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.016201257705688477 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.029947757720947266 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.0 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.021327733993530273 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.014309167861938477 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.034447669982910156 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.02879023551940918 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.03447890281677246 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.035619258880615234 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "writeProfilesToCSV"
source:
@logit
def writeProfilesToCSV(outputFolder, profileDictOut, singleFile=True, strAdd=''):
    """
    Function to write VencoPy profiles to either one or five .csv files in the output folder specified in outputFolder.

    :param outputFolder: Link to output folder
    :param profileDictOut: Dictionary with profile names in keys and profiles as pd.Series containing a VencoPy
    profile each to be written in value
    :param singleFile: If True, all profiles will be appended and written to one .csv file. If False, five files are
    written
    :param strAdd: String addition for filenames
    :return: None
    """

    if singleFile:
        dataOut = pd.DataFrame(profileDictOut)
        dataOut.to_csv(outputFolder + 'vencoOutput' + strAdd + '.csv')
    else:
        for iName, iProf in profileDictOut.items():
            iProf.to_csv(outputFolder + 'vencoOutput_' + iName + strAdd + '.csv')

function call took 0.02571725845336914 ms
exiting function "writeProfilesToCSV"
entering function "linePlot"
source:
@logit
def linePlot(profileDict, linkOutput, show=True, write=True, stradd=''):
    fig, ax = plt.subplots()
    for iKey, iVal in profileDict.items():
        sns.lineplot(iVal.index, iVal, label=iKey, sort=False)
    ax.set_xlabel('Hour')
    ax.set_ylabel('Normalized profiles')
    ax.legend(loc='upper center', ncol=len(profileDict.keys()), bbox_to_anchor=(0.5, 1.1))
    fn = os.path.join(linkOutput, stradd + '.png')
    if show: plt.show()
    if write: fig.savefig(fn)

function call took 16.500509023666382 ms
exiting function "linePlot"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkOutputConfig': vencoConfig['linksRelative']['outputConfig'],
                    'linkOutputAnnual': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.043778181076049805 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.07589912414550781 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.08717513084411621 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.0841531753540039 ms
exiting function "stringToBoolean"
function call took 0.17132830619812012 ms
exiting function "readInputBoolean"
function call took 0.29100561141967773 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.03047776222229004 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.049567461013793945 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.019379138946533203 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 1.0645952224731445 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.039710283279418945 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.1287379264831543 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 1.328005075454712 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.011667966842651367 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.08330774307250977 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.04120802879333496 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.04764127731323242 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.030086040496826172 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.05069684982299805 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.0 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.005634307861328125 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.006258249282836914 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.009438514709472656 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0058863162994384766 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.04926657676696777 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.032026052474975586 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.03657674789428711 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.03331446647644043 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0011632442474365234 ms
exiting function "correctProfiles"
entering function "writeProfilesToCSV"
source:
@logit
def writeProfilesToCSV(outputFolder, profileDictOut, singleFile=True, strAdd=''):
    """
    Function to write VencoPy profiles to either one or five .csv files in the output folder specified in outputFolder.

    :param outputFolder: Link to output folder
    :param profileDictOut: Dictionary with profile names in keys and profiles as pd.Series containing a VencoPy
    profile each to be written in value
    :param singleFile: If True, all profiles will be appended and written to one .csv file. If False, five files are
    written
    :param strAdd: String addition for filenames
    :return: None
    """

    if singleFile:
        dataOut = pd.DataFrame(profileDictOut)
        dataOut.to_csv(outputFolder + 'vencoOutput' + strAdd + '.csv')
    else:
        for iName, iProf in profileDictOut.items():
            iProf.to_csv(outputFolder + 'vencoOutput_' + iName + strAdd + '.csv')

function call took 0.026418209075927734 ms
exiting function "writeProfilesToCSV"
entering function "linePlot"
source:
@logit
def linePlot(profileDict, linkOutput, show=True, write=True, stradd=''):
    fig, ax = plt.subplots()
    for iKey, iVal in profileDict.items():
        sns.lineplot(iVal.index, iVal, label=iKey, sort=False)
    ax.set_xlabel('Hour')
    ax.set_ylabel('Normalized profiles')
    # ax.legend(loc='upper center', ncol=len(profileDict.keys()), bbox_to_anchor=(0.5, 1.1))
    fn = os.path.join(linkOutput, stradd + '.png')
    if show: plt.show()
    if write: fig.savefig(fn)

function call took 15.168114185333252 ms
exiting function "linePlot"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each c
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkOutputConfig': vencoConfig['linksRelative']['outputConfig'],
                    'linkOutputAnnual': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.04255199432373047 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.08362984657287598 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.12023186683654785 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.06737995147705078 ms
exiting function "stringToBoolean"
function call took 0.2032778263092041 ms
exiting function "readInputBoolean"
function call took 0.3302464485168457 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.0176393985748291 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.048436641693115234 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.01675891876220703 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 1.0201356410980225 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.04836583137512207 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.10003376007080078 ms
exiting function "calcDriveProfilesFuelAux"
entering function "calcChargeMinProfiles"
source:
@logit
def calcChargeMinProfiles(chargeProfiles, consumptionProfiles, driveProfilesFuelAux, scalars, scalarsProc, nIter):
    #ToDo param minSecurityFactor
    """
    Calculates minimum SoC profiles assuming that the hourly mileage has to exactly be fulfilled but no battery charge
    is kept inspite of fulfilling the mobility demand. It represents the minimum charge that a vehicle battery has to
    contain in order to fulfill all trips.
    An iteration is performed in order to assure equality of the SoCs at beginning and end of the profile.

    :param chargeProfiles: Charging profiles with techno-economic assumptions on connection power.
    :param consumptionProfiles: Profiles giving consumed electricity for each trip in each hour assuming specified
        consumption.
    :param driveProfilesFuelAux: Auxilliary fuel demand for fulfilling trips if purely electric driving doesn't suffice.
    :param scalars: Techno-economic input assumptions such as consumption, battery capacity etc.
    :param scalarsProc: Number of profiles and number of hours of each profile.
    :param nIter: Gives the number of iterations to fulfill the boundary condition of the SoC equalling in the first
        and in the last hour of the profile.
    :return: Returns an indexed DataFrame containing minimum SOC values for each profile in each hour in the same
        format as chargeProfiles, consumptionProfiles and other input parameters.
    """

    # review general remark: white spaces in column names give me the creeps as it is easy to mistype
    # and create all kind of wired errors.
    # Especially if there are columns with similar names only differing in whitespaces.
    # This is clearly not the case here, but did you consider naming columns with underscores for easier reference?
    chargeMinProfiles = chargeProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    consElectric = scalars.loc['Electric consumption NEFZ', 'value']
    consGasoline = scalars.loc['Fuel consumption NEFZ', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    while idxIt <= nIter:
        for idx in range(nHours):

            # review (resolved) the above nHours implies, that the number of hours can vary based on user input or the
            # underlying data. It seems to me risky to hardcode 23 here if the last hour is meant.
            # Would it not be more prudent to use a variable lastHour that is nHours-1?
            if idx == nHours-1:
                chargeMinProfiles[str(idx)] = np.where(batCapMin <= chargeMinProfiles[str(idx)],
                                                       chargeMinProfiles[str(0)],
                                                       batCapMin)
            else:
                # Calculate and append column with new SOC Max value for comparison and nicer code
                chargeMinProfiles['newCharge'] = chargeMinProfiles[str(idx + 1)] + \
                                                 consumptionProfiles[str(idx + 1)] - \
                                                 chargeProfiles[str(idx + 1)] - \
                                                 (driveProfilesFuelAux[str(idx + 1)] * consElectric / consGasoline)

                # Ensure that chargeMinProfiles values are between batCapMin and batCapMax
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles['newCharge'] >= batCapMin,
                                                       chargeMinProfiles['newCharge'],
                                                       batCapMin)
                chargeMinProfiles[str(idx)] = np.where(chargeMinProfiles[str(idx)] <= batCapMax,
                                                       chargeMinProfiles[str(idx)],
                                                       batCapMax)

        # FixMe Are these 2 lines of further use?
        devCrit = chargeMinProfiles[str(nHours - 1)].sum() - chargeMinProfiles[str(0)].sum()
        print(devCrit)

        idxIt += 1
    chargeMinProfiles.drop('newCharge', axis='columns', inplace=True)
    return chargeMinProfiles

function call took 1.1926555633544922 ms
exiting function "calcChargeMinProfiles"
entering function "createRandNo"
source:
@logit
def createRandNo(driveProfiles, setSeed=1):
    """
    Creates a random number between 0 and 1 for each profile based on driving profiles.

    :param driveProfiles: Dataframe holding hourly electricity consumption values in kWh/h for all profiles
    :param setSeed: Seed for reproducing stochasticity. Scalar number.
    :return: Returns an indexed series with the same indices as dirveProfiles with a random number between 0 and 1 for
    each index.
    """

    idxData = driveProfiles.copy()
    seed(setSeed)  # seed random number generator for reproducibility
    idxData['randNo'] = np.random.random(len(idxData))
    idxData['randNo'] = [random() for _ in range(len(idxData))]  # generate one random number for each profile / index
    randNo = idxData.loc[:, 'randNo']
    return randNo

function call took 0.015651464462280273 ms
exiting function "createRandNo"
entering function "calcProfileSelectors"
source:
@logit
def calcProfileSelectors(chargeProfiles,
                         consumptionProfiles,
                         driveProfiles,
                         driveProfilesFuelAux,
                         randNos,
                         scalars,
                         fuelDriveTolerance,
                         isBEV):
    """
    This function calculates two filters. The first filter, filterCons, excludes profiles that depend on auxiliary
    fuel with an option of a tolerance and those that don't reach a minimum daily average for mileage.
    A second filter filterDSM excludes profiles where the battery doesn't suffice the mileage and those where charging
    throughout the day supplies less energy than necessary for the respective trips.

    :param chargeProfiles: Indexed DataFrame giving hourly charging profiles
    :param consumptionProfiles: Indexed DataFrame giving hourly consumption profiles
    :param driveProfiles:  Indexed DataFrame giving hourly electricity demand profiles for driving.
    :param driveProfilesFuelAux: Indexed DataFrame giving auxiliary fuel demand.
    :param randNos: Indexed Series giving a random number between 0 and 1 for each profiles.
    :param scalars: Techno-economic assumptions
    :param fuelDriveTolerance: Give a threshold value how many liters may be needed throughout the course of a day
    in order to still consider the profile.
    :param isBEV: Boolean value. If true, more 2030 profiles are taken into account (in general).
    :return: The bool indices are written to one DataFrame in the DataManager with the columns randNo, indexCons and
    indexDSM and the same indices as the other profiles.
    """

    boolBEV = scalars.loc['Is BEV?', 'value']
    minDailyMileage = scalars.loc['Minimum daily mileage', 'value']
    batSize = scalars.loc['Battery capacity', 'value']
    socMax = scalars.loc['Maximum SOC', 'value']
    socMin = scalars.loc['Minimum SOC', 'value']
    filterCons = driveProfiles.copy()
    filterCons['randNo'] = randNos
    filterCons['bolFuelDriveTolerance'] = driveProfilesFuelAux.sum(axis='columns') * \
                                           boolBEV < fuelDriveTolerance
    filterCons['bolMinDailyMileage'] = driveProfiles.sum(axis='columns') > \
                                        (2 * randNos * minDailyMileage +
                                         (1 - randNos) * minDailyMileage *
                                         isBEV)
    filterCons['indexCons'] = filterCons.loc[:, 'bolFuelDriveTolerance'] & \
                               filterCons.loc[:, 'bolMinDailyMileage']
    filterCons['bolConsumption'] = consumptionProfiles.sum(axis=1) < \
                                    chargeProfiles.sum(axis=1)
    filterCons['bolSuffBat'] = consumptionProfiles.sum(axis=1) < \
                                batSize * (socMax - socMin)
    filterCons['indexDSM'] = filterCons['indexCons'] & filterCons['bolConsumption'] & filterCons['bolSuffBat']

    print('There are ' + str(sum(filterCons['indexCons'])) + ' considered profiles and ' + \
                    str(sum(filterCons['indexDSM'])) + ' DSM eligible profiles.')
    filterCons_out = filterCons.loc[:, ['randNo', 'indexCons', 'indexDSM']]
    return filterCons_out

function call took 0.07700848579406738 ms
exiting function "calcProfileSelectors"
entering function "calcElectricPowerProfiles"
source:
@logit
def calcElectricPowerProfiles(consumptionProfiles, driveProfilesFuelAux, scalars, filterCons, scalarsProc,
                              filterIndex):
    """
    Calculates electric power profiles that serve as outflow of the fleet batteries.

    :param consumptionProfiles: Indexed DataFrame containing electric vehicle consumption profiles.
    :param driveProfilesFuelAux: Indexed DataFrame containing
    :param scalars: VencoPy Dataframe containing technical assumptions
    :param filterCons: Dataframe containing one boolean filter value for each profile
    :param scalarsProc: Dataframe containing meta information of input profiles
    :param filterIndex: Can be either 'indexCons' or 'indexDSM' so far. 'indexDSM' applies stronger filters and results
    are thus less representative.
    :return: Returns electric demand from driving filtered and aggregated to one fleet.
    """

    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']
    indexCons = filterCons.loc[:, 'indexCons']
    indexDSM = filterCons.loc[:, 'indexDSM']
    nHours = scalarsProc['noHours']
    electricPowerProfiles = consumptionProfiles.copy()
    for iHour in range(nHours):
        electricPowerProfiles[str(iHour)] = (consumptionProfiles[str(iHour)] - driveProfilesFuelAux[str(iHour)] *
                                           (consumptionPower / consumptionFuel))
        if filterIndex == 'indexCons':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexCons
        elif filterIndex == 'indexDSM':
            electricPowerProfiles[str(iHour)] = electricPowerProfiles[str(iHour)] * indexDSM
    return electricPowerProfiles

function call took 0.05367279052734375 ms
exiting function "calcElectricPowerProfiles"
entering function "setUnconsideredBatProfiles"
source:
@logit
def setUnconsideredBatProfiles(chargeMaxProfiles, chargeMinProfiles, filterCons, minValue, maxValue):
    """
    Sets all profile values with filterCons = False to extreme values. For SoC max profiles, this means a value
    that is way higher than SoC max capacity. For SoC min this means usually 0. This setting is important for the
    next step of filtering out extreme values.

    :param chargeMaxProfiles: Dataframe containing hourly maximum SOC profiles for all profiles
    :param chargeMinProfiles: Dataframe containing hourly minimum SOC profiles for all profiles
    :param filterCons: Dataframe containing one boolean value for each profile
    :param minValue: Value that non-reasonable values of SoC min profiles should be set to.
    :param maxValue: Value that non-reasonable values of SoC max profiles should be set to.
    :return: Writes the two profiles files 'chargeMaxProfilesDSM' and 'chargeMinProfilesDSM' to the DataManager.
    """

    chargeMinProfilesDSM = chargeMinProfiles.copy()
    chargeMaxProfilesDSM = chargeMaxProfiles.copy()
    # if len(chargeMaxProfilesCons) == len(filterCons): #len(chargeMaxProfilesCons) = len(chargeMinProfilesCons) by design
    # How can I catch pandas.core.indexing.IndexingError ?
    try:
        chargeMinProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = minValue
        chargeMaxProfilesDSM.loc[~filterCons['indexDSM'].astype('bool'), :] = maxValue
    except Exception as E:
        print("Declaration doesn't work. "
              "Maybe the length of filterCons differs from the length of chargeMaxProfiles")
        raise E
        # raise user defined

    return chargeMaxProfilesDSM, chargeMinProfilesDSM

function call took 0.05038809776306152 ms
exiting function "setUnconsideredBatProfiles"
entering function "indexFilter"
source:
@logit
def indexFilter(chargeMaxProfiles, chargeMinProfiles, filterCons):
    """
    Filters out profiles where indexCons is False.

    :param profiles: Profile keys in DataManager given as list of strings.
    :return: Writes filtered profiles to DataManager under the key 'profilesCons' in a dictionary with keys given
    by parameter profiles.
    """

    profilesFilterConsMin = chargeMinProfiles.loc[filterCons['indexCons'], :]
    profilesFilterConsMax = chargeMaxProfiles.loc[filterCons['indexCons'], :]
    profilesFilterDSMMin = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    profilesFilterDSMMax = chargeMinProfiles.loc[filterCons['indexDSM'], :]
    return profilesFilterConsMin, profilesFilterConsMax, profilesFilterDSMMin, profilesFilterDSMMax

function call took 0.0297091007232666 ms
exiting function "indexFilter"
entering function "socProfileSelection"
source:
@logit
def socProfileSelection(profilesMin, profilesMax, filter, alpha):
    """
    Selects the nth highest value for each hour for min (max profiles based on the percentage given in parameter
    'alpha'. If alpha = 10, the 10%-biggest (10%-smallest) value is selected, all other values are disregarded.
    Currently, in the Venco reproduction phase, the hourly values are selected independently of each other. min and max
    profiles have to have the same number of columns.

    :param profilesMin: Profiles giving minimum hypothetic SOC values to supply the driving demand at each hour
    :param profilesMax: Profiles giving maximum hypothetic SOC values if vehicle is charged as soon as possible
    :param filter: Filter method. Currently implemented: 'singleValue'
    :param alpha: Percentage, giving the amount of profiles whose mobility demand can not be fulfilled after selection.
    :return: Returns the two profiles 'SOCMax' and 'SOCMin' in the same time resolution as input profiles.
    """

    noProfiles = len(profilesMin)
    noProfilesFilter = int(alpha / 100 * noProfiles)
    if filter == 'singleValue':
        profileMinOut = profilesMin.iloc[0, :].copy()
        for col in profilesMin:
            profileMinOut[col] = min(profilesMin[col].nlargest(noProfilesFilter))

        profileMaxOut = profilesMax.iloc[0, :].copy()
        for col in profilesMax:
            profileMaxOut[col] = max(profilesMax[col].nsmallest(noProfilesFilter))

    else:
        # review have you considered implementing your own error like class FilterError(Exception):
        # pass which would give the user an additional hint on what went wrong?
        raise ValueError('You selected a filter method that is not implemented.')
    return profileMinOut, profileMaxOut

function call took 0.03279733657836914 ms
exiting function "socProfileSelection"
entering function "normalizeProfiles"
source:
@logit
def normalizeProfiles(scalars, socMin, socMax, normReferenceParam):
    # ToDo: Implement a normalization to the maximum of a given profile

    """
    Normalizes given profiles with a given scalar reference.

    :param scalars: Dataframe containing technical assumptions e.g. battery capacity
    :param socMin: Minimum SOC profile subject to normalization
    :param socMax: Minimum SOC profile subject to normalization
    :param normReferenceParam: Reference parameter that is taken for normalization.
    This has to be given in scalar input data and is most likely the battery capacity.
    :return: Writes the normalized profiles to the DataManager under the specified keys
    """

    normReference = scalars.loc[normReferenceParam, 'value']
    try:
        socMinNorm = socMin.div(float(normReference))
        socMaxNorm = socMax.div(float(normReference))

    except ValueError:
        # review general if " is used instead of ' the escaping of \' is not necessary
        # review general so is this not a problem at all if this happens?
        # s I understand this code, socMin and socMax would be unchanged by this function call
        print('There was a value error. I don\'t know what to tell you.')
    return socMinNorm, socMaxNorm

function call took 0.015854597091674805 ms
exiting function "normalizeProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0010104179382324219 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.015940427780151367 ms
exiting function "filterConsProfiles"
entering function "filterConsProfiles"
source:
@logit
def filterConsProfiles(profile, filterCons, critCol):
    """
    Filter out all profiles from given profile types whose boolean indices (so far DSM or cons) are FALSE.

    :param profile: Dataframe of hourly values for all filtered profiles
    :param filterCons: Identifiers given as list of string to store filtered profiles back into the DataManager
    :param critCol: Criterium column for filtering
    :return: Stores filtered profiles in the DataManager under keys given in dmgrNames
    """

    outputProfile = profile.loc[filterCons[critCol], :]
    return outputProfile

function call took 0.0009968280792236328 ms
exiting function "filterConsProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.0469517707824707 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.03721261024475098 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.03144669532775879 ms
exiting function "aggregateProfiles"
entering function "aggregateProfiles"
source:
@logit
def aggregateProfiles(profilesIn):
    """
    This method aggregates all single-vehicle profiles that are considered to one fleet profile.

    :param profilesIn: Dataframe of hourly values of all filtered profiles
    :return: Returns a Dataframe with hourly values for one aggregated profile
    """

    # Typecasting is necessary for aggregation of boolean profiles
    profilesOut = profilesIn.iloc[0, :].astype('float64', copy=True)
    lenProfiles = len(profilesIn)

    # review have you considered using pandas dataframe .T to transpose,
    # use sum to get the sum of each column and then divide by lenProfiles?
    # This would be more concise in writing and more performant than a python loop
    for colidx in profilesIn:
        profilesOut[colidx] = sum(profilesIn.loc[:, colidx]) / lenProfiles
    return profilesOut

function call took 0.030969619750976562 ms
exiting function "aggregateProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "correctProfiles"
source:
@logit
def correctProfiles(scalars, profile, profType):
    """
    This method scales given profiles by a correction factor. It was written for VencoPy scaling consumption data
    with the more realistic ARTEMIS driving cycle.

    :param scalars: Dataframe of technical assumptions
    :param profile: Dataframe of profile that should be corrected
    :param profType: A list of strings specifying if the given profile type is an electric or a fuel profile.
    profType has to have the same length as profiles.
    :return:
    """

    profileOut = profile.copy()
    if profType == 'electric':
        consumptionElectricNEFZ = scalars.loc['Electric consumption NEFZ', 'value']
        consumptionElectricArtemis = scalars.loc['Electric consumption Artemis', 'value']
        corrFactor = consumptionElectricArtemis / consumptionElectricNEFZ

    elif profType == 'fuel':
        consumptionFuelNEFZ = scalars.loc['Fuel consumption NEFZ', 'value']
        consumptionFuelArtemis = scalars.loc['Fuel consumption Artemis', 'value']
        corrFactor = consumptionFuelArtemis / consumptionFuelNEFZ

    else:
        # review I expect raising an exception here. Would it not be a problem if the processing continues silently?
        print('Either parameter "profType" is not given or not assigned to either "electric" or "fuel".')

    # review same like above:
    # review have you considered using pandas dataframe .T to transpose, use sum to get the sum of each column and
    # then divide by lenProfiles? This would be more concise in writing and more performant than a python loop
    for colIdx in profile.index:
        profileOut[colIdx] = corrFactor * profile[colIdx]
    return profileOut

function call took 0.0 ms
exiting function "correctProfiles"
entering function "writeProfilesToCSV"
source:
@logit
def writeProfilesToCSV(outputFolder, profileDictOut, singleFile=True, strAdd=''):
    """
    Function to write VencoPy profiles to either one or five .csv files in the output folder specified in outputFolder.

    :param outputFolder: Link to output folder
    :param profileDictOut: Dictionary with profile names in keys and profiles as pd.Series containing a VencoPy
    profile each to be written in value
    :param singleFile: If True, all profiles will be appended and written to one .csv file. If False, five files are
    written
    :param strAdd: String addition for filenames
    :return: None
    """

    if singleFile:
        dataOut = pd.DataFrame(profileDictOut)
        dataOut.to_csv(outputFolder + 'vencoOutput' + strAdd + '.csv')
    else:
        for iName, iProf in profileDictOut.items():
            iProf.to_csv(outputFolder + 'vencoOutput_' + iName + strAdd + '.csv')

function call took 0.02353358268737793 ms
exiting function "writeProfilesToCSV"
entering function "linePlot"
source:
@logit
def linePlot(profileDict, linkOutput, show=True, write=True, stradd=''):
    fig, ax = plt.subplots()
    for iKey, iVal in profileDict.items():
        sns.lineplot(iVal.index, iVal, label=iKey, sort=False)
    ax.set_xlabel('Hour')
    ax.set_ylabel('Normalized profiles')
    ax.legend(loc='upper center', ncol=2, bbox_to_anchor=(0.5, 1.1))
    fn = os.path.join(linkOutput, stradd + '.png')
    if show: plt.show()
    if write: fig.savefig(fn)

function call took 36.798112869262695 ms
exiting function "linePlot"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkOutputConfig': vencoConfig['linksRelative']['outputConfig'],
                    'linkOutputAnnual': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    scalarInput = Assumptions
    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.10937190055847168 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.1093757152557373 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.1406252384185791 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.0937492847442627 ms
exiting function "stringToBoolean"
function call took 0.24999737739562988 ms
exiting function "readInputBoolean"
function call took 0.49999356269836426 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.015628814697265625 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.062499284744262695 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.031252384185791016 ms
exiting function "calcChargeProfiles"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkOutputConfig': vencoConfig['linksRelative']['outputConfig'],
                    'linkOutputAnnual': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    scalarInput = Assumptions
    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.03125286102294922 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.09375119209289551 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.10937190055847168 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.07812380790710449 ms
exiting function "stringToBoolean"
function call took 0.20312070846557617 ms
exiting function "readInputBoolean"
function call took 0.3281247615814209 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.031248092651367188 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.06254124641418457 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.015625 ms
exiting function "calcChargeProfiles"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkOutputConfig': vencoConfig['linksRelative']['outputConfig'],
                    'linkOutputAnnual': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    scalarInput = Assumptions
    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.015625 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.09427142143249512 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.1249997615814209 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.07812213897705078 ms
exiting function "stringToBoolean"
function call took 0.21875357627868652 ms
exiting function "readInputBoolean"
function call took 0.3755462169647217 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.01563239097595215 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.04688572883605957 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.031247377395629883 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 1.0920052528381348 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 5.473758935928345 ms
exiting function "calcChargeMaxProfiles"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.06249833106994629 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.031248807907104492 ms
exiting function "calcChargeProfiles"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.06250882148742676 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.031249284744262695 ms
exiting function "calcChargeProfiles"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.06246519088745117 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.015630006790161133 ms
exiting function "calcChargeProfiles"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.0625004768371582 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.03125 ms
exiting function "calcChargeProfiles"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.06246519088745117 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.031290292739868164 ms
exiting function "calcChargeProfiles"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.04690122604370117 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.031222105026245117 ms
exiting function "calcChargeProfiles"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.04687333106994629 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.015625 ms
exiting function "calcChargeProfiles"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.04687356948852539 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.015635251998901367 ms
exiting function "calcChargeProfiles"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.062499046325683594 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.031261444091796875 ms
exiting function "calcChargeProfiles"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.04690289497375488 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.03125309944152832 ms
exiting function "calcChargeProfiles"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.0468745231628418 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.015626907348632812 ms
exiting function "calcChargeProfiles"
entering function "calcConsumptionProfiles"
source:
@logit
def calcConsumptionProfiles(driveProfiles, scalars):
    """
    Calculates electrical consumption profiles from drive profiles assuming specific consumption (in kWh/100 km)
    given in scalar input data file.

    :param driveProfiles: indexed profile file
    :param Scalars: dataframe holding technical assumptions
    :return: Returns a dataframe with consumption profiles in kWh/h in same format and length as driveProfiles but
    scaled with the specific consumption assumption.
    """

    consumptionProfiles = driveProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    # review the division by int 100 can be changed to float 100. which would force python above 2.7 to use float
    # division and thus a typecast might not even be necessary
    # consumptionProfiles = consumptionProfiles * float(scalars.loc['Electric consumption NEFZ', 'value']) / 100
    consumptionProfiles = consumptionProfiles * scalars.loc['Electric consumption NEFZ', 'value'] / float(100)
    return consumptionProfiles

function call took 0.04690957069396973 ms
exiting function "calcConsumptionProfiles"
entering function "calcChargeProfiles"
source:
@logit
def calcChargeProfiles(plugProfiles, scalars):
    '''
    Calculates the maximum possible charge power based on the plug profile assuming the charge column power
    given in the scalar input data file (so far under Panschluss).

    :param plugProfiles: indexed boolean profiles for vehicle connection to grid
    :param scalars: VencoPy scalar dataframe
    :return: Returns scaled plugProfile in the same format as plugProfiles.
    '''

    chargeProfiles = plugProfiles.copy()
    # review have you considered the pandas .astype() method? It is more performant than a direct float type cast.
    chargeProfiles = chargeProfiles * float(scalars.loc['Rated power of charging column', 'value'])
    return chargeProfiles

function call took 0.01562952995300293 ms
exiting function "calcChargeProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 5.593747854232788 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeMaxProfiles"
source:
@logit
def calcChargeMaxProfiles(chargeProfiles, consumptionProfiles, scalars, scalarsProc, nIter):
    """
    Calculates all maximum SoC profiles under the assumption that batteries are always charged as soon as they
    are plugged to the grid. Values are assured to not fall below SoC_min * battery capacity or surpass
    SoC_max * battery capacity. Relevant profiles are chargeProfile and consumptionProfile. An iteration assures
    the boundary condition of chargeMaxProfile(0) = chargeMaxProfile(len(profiles)). The number of iterations
    is given as parameter.

    :param chargeProfiles: Indexed dataframe of charge profiles.
    :param consumptionProfiles: Indexed dataframe of consumptionProfiles.
    :param scalars: DataFrame holding techno-economic assumptions.
    :param scalarsProc: DataFrame holding information about profile length and number of hours.
    :param nIter: Number of iterations to assure that the minimum and maximum value are approximately the same
    :return: Returns an indexed DataFrame with the same length and form as chargProfiles and consumptionProfiles,
    containing single-profile SOC max values for each hour in each profile.
    """

    chargeMaxProfiles = chargeProfiles.copy()
    chargeProfiles = chargeProfiles.copy()
    consumptionProfiles = consumptionProfiles.copy()
    batCapMin = scalars.loc['Battery capacity', 'value'] * scalars.loc['Minimum SOC', 'value']
    batCapMax = scalars.loc['Battery capacity', 'value'] * scalars.loc['Maximum SOC', 'value']
    nHours = scalarsProc['noHours']
    idxIt = 1
    for idxIt in range(nIter):
        # ToDo: np.where() replace by pd.something(),
        # ToDo: prohibit typecasting str(idx) in data preparation step colnames as integers {smell} in function indexProfiles()
        for idx in range(nHours):
            # testing line
            # chargeMaxProfiles.ix[3, '0'] = 15.0
            if idx == 0:
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
                                                      chargeMaxProfiles[str(nHours - 1)],
                                                      batCapMax)
            else:
                # Calculate and append column with new SoC Max value for comparison and cleaner code
                chargeMaxProfiles['newCharge'] = chargeMaxProfiles[str(idx - 1)] + \
                                                chargeProfiles[str(idx)] - \
                                                consumptionProfiles[str(idx)]

                # Ensure that chargeMaxProfiles values are between batCapMin and batCapMax
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles['newCharge'] <= batCapMax,
                                                      chargeMaxProfiles['newCharge'],
                                                      batCapMax)
                chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] >= batCapMin,
                                                      chargeMaxProfiles[str(idx)],
                                                      batCapMin)

        # review: general remark instead of str(0) which is a performance heavy operation, one could write "0" which is equivalent and less performance heavy (performance impact is however negligible I guess)
        devCrit = chargeMaxProfiles[str(nHours - 1)].sum() - chargeMaxProfiles[str(0)].sum()
        print(devCrit)
        idxIt += 1
    chargeMaxProfiles.drop(labels='newCharge', axis='columns', inplace=True)
    return chargeMaxProfiles

function call took 5.484411954879761 ms
exiting function "calcChargeMaxProfiles"
entering function "calcChargeProfilesUncontrolled"
source:
@logit
def calcChargeProfilesUncontrolled(chargeMaxProfiles, scalarsProc):
    """
    Calculates uncontrolled electric charging based on SoC Max profiles for each hour for each profile.

    :param chargeMaxProfiles: Dataframe holding timestep dependent SOC max values for each profile.
    :param scalarsProc: VencoPy Dataframe holding meta-information about read-in profiles.
    :return: Returns profiles for uncontrolled charging under the assumption that charging occurs as soon as a
    vehicle is connected to the grid up to the point that the maximum battery SOC is reached or the connection
    is interrupted. DataFrame has the same format as chargeMaxProfiles.
    """

    chargeMaxProfiles = chargeMaxProfiles.copy()
    chargeProfilesUncontrolled = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    for idx in range(nHours):

        if idx != 0:
            chargeProfilesUncontrolled[str(idx)] = np.where(
                chargeMaxProfiles[str(idx)] >= chargeMaxProfiles[str(idx - 1)],
                chargeMaxProfiles[str(idx)] - chargeMaxProfiles[str(idx - 1)],
                0)

    # set value of uncontrolled charging for first hour to average between hour 1 and hour 23
    # because in calcChargeMax iteration the difference is minimized.
    chargeProfilesUncontrolled[str(0)] = \
        (chargeProfilesUncontrolled[str(1)] + chargeProfilesUncontrolled[str(nHours - 1)]) / 2
    return chargeProfilesUncontrolled

function call took 0.046872615814208984 ms
exiting function "calcChargeProfilesUncontrolled"
entering function "calcDriveProfilesFuelAux"
source:
@logit
def calcDriveProfilesFuelAux(chargeMaxProfiles, chargeProfilesUncontrolled, driveProfiles, scalars, scalarsProc):
    #ToDo: alternative vectorized format for looping over columns? numpy, pandas: broadcasting-rules
    """
     Calculates necessary fuel consumption profile of a potential auxilliary unit (e.g. a gasoline motor) based
    on gasoline consumption given in scalar input data (in l/100 km). Auxilliary fuel is needed if an hourly
    mileage is higher than the available SoC Max in that hour.

    :param chargeMaxProfiles: Dataframe holding hourly maximum SOC profiles in kWh for all profiles
    :param chargeProfilesUncontrolled: Dataframe holding hourly uncontrolled charging values in kWh/h for all profiles
    :param driveProfiles: Dataframe holding hourly electric driving demand in kWh/h for all profiles.
    :param scalars: Dataframe holding technical assumptions
    :param scalarsProc: Dataframe holding meta-infos about the input
    :return: Returns a DataFrame with single-profile values for back-up fuel demand in the case a profile cannot
    completely be fulfilled with electric driving under the given consumption and battery size assumptions.
    """

    # review: the hardcoding of the column names can cause a lot of problems for people later on if we do not ship the date with the tool.
    # I would recommend to move these column names to a config file similar to i18n strategies
    consumptionPower = scalars.loc['Electric consumption NEFZ', 'value']
    consumptionFuel = scalars.loc['Fuel consumption NEFZ', 'value']

    # initialize data set for filling up later on
    driveProfilesFuelAux = chargeMaxProfiles.copy()
    nHours = scalarsProc['noHours']

    # review (resolved): have you considered naming idx into ihour as it actually contains the currently processed hour and would make the code more readable
    for iHour in range(nHours):
        # review as far as I can tell, the hour 0 is never filled or added as a column to driveProfilesFuelAux. But this should raise an error in line 336 for idx 1. Why does this work anyhow?
        if iHour != 0:
            driveProfilesFuelAux[str(iHour)] = (consumptionFuel / consumptionPower) * \
                                             (driveProfiles[str(iHour)] * consumptionPower / 100 -
                                              chargeProfilesUncontrolled[str(iHour)] -
                                              (chargeMaxProfiles[str(iHour - 1)] - chargeMaxProfiles[str(iHour)]))

    # Setting value of hour=0 equal to the average of hour=1 and last hour
    driveProfilesFuelAux[str(0)] = (driveProfilesFuelAux[str(nHours - 1)] + driveProfilesFuelAux[str(1)]) / 2
    driveProfilesFuelAux = driveProfilesFuelAux.round(4)
    return driveProfilesFuelAux

function call took 0.1093740463256836 ms
exiting function "calcDriveProfilesFuelAux"
entering function "readVencoInput"
source:
@logit
def readVencoInput(config):
    """
    Initializing action for VencoPy-specific config-file, link dictionary and data read-in. The config file has
    to be a dictionary in a .yaml file containing three categories: linksRelative, linksAbsolute and files. Each
    category must contain itself a dictionary with the linksRelative to data, functions, plots, scripts, config and
    tsConfig. Absolute links should contain the path to the output folder. Files should contain a link to scalar input
    data, and the two timeseries files inputDataDriveProfiles and inputDataPlugProfiles.

    :param config: A yaml config file holding a dictionary with the keys "linksRelative" and "linksAbsolute"
    :return: Returns four dataframes: A link dictionary, scalars, drive profile data and plug profile
    data, the latter three ones in a raw data format.
    """

    linkDict = initializeLinkMgr(config)

    # review: have you considered using the logging module for these kind of outputs?
    print('Reading Venco input scalars, drive profiles and boolean plug profiles')

    scalars = readInputScalar(linkDict['linkScalars'])
    driveProfiles_raw = readInputCSV(linkDict['linkDriveProfiles'])
    plugProfiles_raw = readInputBoolean(linkDict['linkPlugProfiles'])

    print('There are ' + str(len(driveProfiles_raw)) + ' drive profiles and ' +
                    str(len(driveProfiles_raw)) + ' plug profiles.')

    return linkDict, scalars, driveProfiles_raw, plugProfiles_raw

entering function "initializeLinkMgr"
source:
@logit
def initializeLinkMgr(vencoConfig):
    """
    Setup link manager based on a VencoPy config file.

    :param vencoConfig: Config file initiated by a yaml-loader

    :return: Returns link dictionary with relative links to input data and output folders.
    """
    linkDict = {'linkScalars': vencoConfig['linksRelative']['input'] + vencoConfig['files']['inputDataScalars'],
                    'linkDriveProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataDriveProfiles"],
                    'linkPlugProfiles': vencoConfig['linksRelative']['input'] + vencoConfig['files'][
                        "inputDataPlugProfiles"],
                    'linkOutputConfig': vencoConfig['linksRelative']['outputConfig'],
                    'linkOutputAnnual': vencoConfig['linksRelative']['resultsAnnual'],
                    'linkPlots': vencoConfig['linksRelative']['plots'],
                    'linkOutput': vencoConfig['linksRelative']['resultsDaily']}
    return linkDict

function call took 0.0 ms
exiting function "initializeLinkMgr"
entering function "readInputScalar"
source:
@logit
def readInputScalar(filePath):
    """
    Method that gets the path to a venco scalar input file specifying technical assumptions such as battery capacity
    specific energy consumption, usable battery capacity share for load shifting and charge power.

    :param filePath: The relative file path to the input file
    :return: Returns a dataframe with an index column and two value columns. The first value column holds numbers the
        second one holds units.
    """

    scalarInput = Assumptions
    inputRaw = pd.read_excel(filePath,
                              header=5,
                              usecols="A:C",
                              skiprows=0)
    scalarsOut = inputRaw.set_index('parameter')
    return scalarsOut

function call took 0.05199718475341797 ms
exiting function "readInputScalar"
entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.19699907302856445 ms
exiting function "readInputCSV"
entering function "readInputBoolean"
source:
@logit
def readInputBoolean(filePath):
    """
    Wrapper function for reading boolean data from CSV.

    :param filePath: Relative path to CSV file
    :return: Returns a dataframe with boolean values
    """

    inputRaw = readInputCSV(filePath)
    inputData = stringToBoolean(inputRaw)
    return inputData

entering function "readInputCSV"
source:
@logit
def readInputCSV(filePath):
    """
    Reads input and cuts out value columns from a given CSV file.

    :param filePath: Relative file path to CSV file
    :return: Pandas dataframe with raw input from CSV file
    """
    inputRaw = pd.read_csv(filePath, header=0)
    inputData = inputRaw.loc[:, ~inputRaw.columns.str.match('Unnamed')]
    return inputData

function call took 0.19599699974060059 ms
exiting function "readInputCSV"
entering function "stringToBoolean"
source:
@logit
def stringToBoolean(df):
    """
    Replaces given strings with python values for true or false.
    FixMe: Foreseen to be more flexible in next release.

    :param df: Dataframe holding strings defining true or false values
    :return: Dataframe holding true and false
    """

    dictBol = {'WAHR': True,
                'FALSCH': False}
    outBool = df.replace(to_replace=dictBol, value=None)
    return (outBool)

function call took 0.11999773979187012 ms
exiting function "stringToBoolean"
function call took 0.3479938507080078 ms
exiting function "readInputBoolean"
function call took 0.649000883102417 ms
exiting function "readVencoInput"
entering function "indexProfile"
source:
@logit
def indexProfile(driveProfiles_raw, plugProfiles_raw, indices):
    """
    Takes raw data as input and indices different profiles with the specified index columns und an unstacked form.

    :param driveProfiles_raw: Dataframe of raw drive profiles in km with as many index columns as elements
        of the list in given in indices. One column represents one timestep, e.g. hour.
    :param plugProfiles_raw: Dataframe of raw plug profiles as boolean values with as many index columns
        as elements of the list in given in indices. One column represents one timestep e.g. hour.
    :param indices: List of column names given as strings.
    :return: Two indexed dataframes with index columns as given in argument indices separated from data columns
    """

    driveProfiles = driveProfiles_raw.set_index(list(indices))
    plugProfiles = plugProfiles_raw.set_index(list(indices))
    return driveProfiles, plugProfiles

function call took 0.027999162673950195 ms
exiting function "indexProfile"
entering function "procScalars"
source:
@logit
def procScalars(driveProfiles_raw, plugProfiles_raw, driveProfiles, plugProfiles):
    """
    Calculates some scalars from the input data such as the number of hours of drive and plug profiles, the number of
    profiles etc.

    :param driveProfiles: Input drive profile input data frame with timestep specific driving distance in km
    :param plugProfiles: Input plug profile input data frame with timestep specific boolean grid connection values
    :return: Returns a dataframe of processed scalars including number of profiles and number of hours per profile
    """

    noHoursDrive = len(driveProfiles.columns)
    noHoursPlug = len(plugProfiles.columns)
    noDriveProfilesIn = len(driveProfiles)
    noPlugProfilesIn = len(plugProfiles)
    scalarsProc = {'noHoursDrive': noHoursDrive,
                   'noHoursPlug': noHoursPlug,
                   'noDriveProfilesIn': noDriveProfilesIn,
                   'noPlugProfilesIn': noPlugProfilesIn}
    if noHoursDrive == noHoursPlug:
        scalarsProc['noHours'] = noHoursDrive
    else:
        warnings.warn('Length of drive and plug input data differ! This will at the latest crash in calculating '
                      'profiles for SoC max')
    return scalarsProc

function call took 0.0 ms
exiting function "procScalars"
Error during call of function "calcChargeMaxProfiles"
Traceback (most recent call last):
  File "C:\Program Files\JetBrains\PyCharm Community Edition 2019.1.3\helpers\pydev\_pydevd_bundle\pydevd_vars.py", line 410, in evaluate_expression
    compiled = compile(expression, '<string>', 'eval')
  File "<string>", line 1
    chargeMaxProfiles = calcChargeMaxProfiles(chargeProfiles,
                      ^
SyntaxError: invalid syntax

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Miniconda3\envs\VencoPy\lib\site-packages\pandas\core\indexes\base.py", line 2897, in get_loc
    return self._engine.get_loc(key)
  File "pandas\_libs\index.pyx", line 107, in pandas._libs.index.IndexEngine.get_loc
  File "pandas\_libs\index.pyx", line 128, in pandas._libs.index.IndexEngine.get_loc
  File "pandas\_libs\index_class_helper.pxi", line 91, in pandas._libs.index.Int64Engine._check_type
KeyError: '0'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\vencopy_repo\scripts\libLogging.py", line 32, in wrapper
    ret = f(*args, **kwargs)
  File "C:\vencopy_repo\scripts\libProfileCalculation.py", line 88, in calcChargeMaxProfiles
    chargeMaxProfiles[str(idx)] = np.where(chargeMaxProfiles[str(idx)] <= batCapMax,
  File "C:\ProgramData\Miniconda3\envs\VencoPy\lib\site-packages\pandas\core\frame.py", line 2995, in __getitem__
    indexer = self.columns.get_loc(key)
  File "C:\ProgramData\Miniconda3\envs\VencoPy\lib\site-packages\pandas\core\indexes\base.py", line 2899, in get_loc
    return self._engine.get_loc(self._maybe_cast_indexer(key))
  File "pandas\_libs\index.pyx", line 107, in pandas._libs.index.IndexEngine.get_loc
  File "pandas\_libs\index.pyx", line 128, in pandas._libs.index.IndexEngine.get_loc
  File "pandas\_libs\index_class_helper.pxi", line 91, in pandas._libs.index.Int64Engine._check_type
KeyError: '0'
Error during call of function "writeProfilesToCSV"
Traceback (most recent call last):
  File "C:\vencopy_repo\scripts\libLogging.py", line 32, in wrapper
    ret = f(*args, **kwargs)
  File "C:\vencopy_repo\scripts\libOutput.py", line 134, in writeProfilesToCSV
    iProf.to_csv(outputFolder + 'vencoOutput_' + iName + strAdd + '.csv', header=True)
TypeError: unsupported operand type(s) for +: 'WindowsPath' and 'str'
Error during call of function "writeProfilesToCSV"
Traceback (most recent call last):
  File "C:\vencopy_repo\scripts\libLogging.py", line 32, in wrapper
    ret = f(*args, **kwargs)
  File "C:\vencopy_repo\scripts\libOutput.py", line 134, in writeProfilesToCSV
    iProf.to_csv(outputFolder / 'vencoOutput_' + iName + strAdd + '.csv', header=True)
TypeError: unsupported operand type(s) for +: 'WindowsPath' and 'str'
